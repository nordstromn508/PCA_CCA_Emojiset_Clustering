{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 207,
   "id": "53adcf77-0220-46ab-9b5b-2c266d408a56",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sn\n",
    "from random import shuffle\n",
    "import os\n",
    "from sklearn.datasets import make_blobs\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "import random\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.layers import Input, Conv2D, Dense, Flatten, Dropout, GlobalMaxPooling2D, MaxPooling2D, BatchNormalization\n",
    "from tensorflow.keras.models import Sequential, load_model\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.utils import to_categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "id": "253b3b31-4a37-4938-8458-15c321b497e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_dataset(n_clusters: int, n_points: int = 100, std: float = 1.0, min: float = -10, max: float = 10, random_state : int = None):\n",
    "    \"\"\"\n",
    "    generates a two dimensional set of points\n",
    "    :param n_clusters: number of clusters to generate\n",
    "    :param n_points: number of total points to generate for all clusters\n",
    "    :param std: standard deviation of cluster points\n",
    "    :param min: minimum point value\n",
    "    :param max: maximum point value\n",
    "    :param random_state: random generator seed\n",
    "    :return: X, array of points shape (n_points, 2)\n",
    "    :return: y, array of point cluster identity\n",
    "    :return: centers, center point for each cluster\n",
    "    \"\"\"\n",
    "    X, y, centers = make_blobs(n_samples=n_points, n_features=2, centers=n_clusters, cluster_std=std, center_box=(min, max), return_centers=True, random_state=random_state)\n",
    "    return X, y, centers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "id": "b0a9e55b-af43-48ac-9e3d-edbeb945a885",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Requirements:\n",
    "the input plot must without axes\n",
    "\"\"\"\n",
    "# Generate and save plot without axes\n",
    "def generate_save_plot(n_clusters, n_points, std, random_state, plot_path, show=True):\n",
    "    X, y, centers = generate_dataset(\n",
    "        n_clusters = n_clusters, \n",
    "        n_points = n_points,\n",
    "        std = std,\n",
    "        random_state = random_state\n",
    "    )\n",
    "    plt.scatter(X[:, 0], X[:, 1])\n",
    "    plt.axis('off') # to save plot without axes\n",
    "    plt.savefig(plot_path)\n",
    "    if show: plt.show()\n",
    "    plt.clf()\n",
    "    \n",
    "    \n",
    "    \n",
    "# Load the image and convert to binary\n",
    "def get_binary_plot(path):\n",
    "    plot = cv2.imread(path, cv2.IMREAD_GRAYSCALE)\n",
    "    bp = plot\n",
    "    bp[plot == 255] = 0;\n",
    "    bp[plot>0] = 255;\n",
    "    return bp\n",
    "\n",
    "\n",
    "\n",
    "# Generate random data for 2-n_clusters, each category has n_samples, out to specific folder\n",
    "def generate_data(n_clusters, n_samples, folder):\n",
    "    total_samples = (n_clusters - 1) * n_samples\n",
    "    random_seeds = random.sample(range(total_samples * 10), total_samples)\n",
    "    seed_index = 0\n",
    "    for i in range(2, n_clusters + 1):\n",
    "        for j in range(n_samples):\n",
    "            seed = random_seeds[seed_index]\n",
    "#             random_std = round(random.uniform(1.0), 2) # from 0.5-1.5\n",
    "            random_points = random.randint(i*10, 1*100)\n",
    "            generate_save_plot(i, random_points, 1.0, seed, \n",
    "                               '../plots/{}/{}_{}.png'.format(folder, i, j), False)\n",
    "            seed_index += 1\n",
    "            \n",
    "\n",
    "            \n",
    "# Load images to array and also its corresponding labels          \n",
    "def load_data(folder):\n",
    "    x = []\n",
    "    y = []\n",
    "    for image_name in os.listdir(folder):\n",
    "        if \".png\" in image_name:\n",
    "            image_name_split = image_name.split('_')\n",
    "            img_path = os.path.join(folder, image_name)\n",
    "            img = get_binary_plot(img_path)\n",
    "            resized = cv2.resize(img, (48,48), interpolation=cv2.INTER_AREA) # resize to 32 * 32\n",
    "            scaled = resized/255.0 # rescale\n",
    "            x.append(scaled)\n",
    "            y.append(int(image_name_split[0])*1.0) # make the label as float for regression appraoch perform better\n",
    "        else: \n",
    "            continue\n",
    "    x = np.array(x)\n",
    "    y = np.array(y)\n",
    "    print(x.shape)\n",
    "    print(y.shape)\n",
    "    return x, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "id": "6335a18b-9e00-4ade-9b66-16ba26ef7a7e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "generate_data(6, 300, 'training')\n",
    "generate_data(6, 60, 'validation')\n",
    "# generate_data(6, 50, 'test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "id": "3e720f9a-aba8-4c86-9b50-568b12386b19",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1500, 48, 48)\n",
      "(1500,)\n",
      "(300, 48, 48)\n",
      "(300,)\n",
      "(250, 48, 48)\n",
      "(250,)\n"
     ]
    }
   ],
   "source": [
    "size = 48\n",
    "train_x, train_y = load_data('../plots/training')\n",
    "val_x, val_y = load_data('../plots/validation')\n",
    "test_x, test_y = load_data('../plots/test')\n",
    "train_x = train_x.reshape(-1, size, size, 1)\n",
    "val_x = val_x.reshape(-1, size, size, 1)\n",
    "test_x = test_x.reshape(-1, size, size, 1)\n",
    "\n",
    "# classification need one hot encoding\n",
    "# train_y = to_categorical(train_y)\n",
    "# val_y = to_categorical(val_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "id": "b6580db6-321f-4a1c-bb6d-d192f660fc15",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model(input_shape=(48,48,1), alpha=0.0001):\n",
    "    # Build CNN model\n",
    "    model = Sequential()\n",
    "    model.add(Conv2D(input_shape=input_shape, filters = 32, kernel_size=(3, 3), activation='relu', padding='same')) \n",
    "    model.add(Conv2D(32, (3, 3), activation='relu', padding='same'))\n",
    "    model.add(MaxPooling2D((2, 2)))\n",
    "\n",
    "    model.add(Conv2D(64, (3, 3), activation='relu', padding='same'))\n",
    "    model.add(MaxPooling2D((2, 2)))\n",
    "\n",
    "    model.add(Conv2D(128, (3, 3), activation='relu', padding='same'))\n",
    "    model.add(MaxPooling2D((2, 2)))\n",
    "    \n",
    "#     model.add(Conv2D(256, (3, 3), activation='relu', padding='same'))\n",
    "#     model.add(MaxPooling2D((2, 2)))\n",
    "\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(256, activation='relu'))\n",
    "    model.add(BatchNormalization())\n",
    "#     model.add(Dense(256, activation='relu'))\n",
    "#     model.add(BatchNormalization())\n",
    "#     model.add(Dense(7, activation='softmax')) # classification\n",
    "    model.add(Dense(1)) # regression\n",
    "    \n",
    "    # classification approach\n",
    "#     model.compile(\n",
    "#         loss='categorical_crossentropy',\n",
    "#         optimizer=Adam(lr=alpha),\n",
    "#         metrics=['accuracy']\n",
    "#     )\n",
    "    \n",
    "    # reg approach\n",
    "    model.compile(\n",
    "        loss='mean_absolute_error',\n",
    "        optimizer=Adam(lr=alpha),\n",
    "        metrics=['mae']\n",
    "    )\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "id": "256cdabc-a7bb-404c-85b4-0cf95c6c218c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/zhihengchang/opt/anaconda3/lib/python3.8/site-packages/keras/optimizer_v2/optimizer_v2.py:355: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/300\n",
      "12/12 [==============================] - 4s 288ms/step - loss: 3.9889 - mae: 3.9889 - val_loss: 3.9655 - val_mae: 3.9655\n",
      "Epoch 2/300\n",
      "12/12 [==============================] - 3s 277ms/step - loss: 3.9635 - mae: 3.9635 - val_loss: 3.9413 - val_mae: 3.9413\n",
      "Epoch 3/300\n",
      "12/12 [==============================] - 3s 279ms/step - loss: 3.9371 - mae: 3.9371 - val_loss: 3.9147 - val_mae: 3.9147\n",
      "Epoch 4/300\n",
      "12/12 [==============================] - 3s 276ms/step - loss: 3.9095 - mae: 3.9095 - val_loss: 3.8876 - val_mae: 3.8876\n",
      "Epoch 5/300\n",
      "12/12 [==============================] - 3s 282ms/step - loss: 3.8806 - mae: 3.8806 - val_loss: 3.8566 - val_mae: 3.8566\n",
      "Epoch 6/300\n",
      "12/12 [==============================] - 3s 285ms/step - loss: 3.8501 - mae: 3.8501 - val_loss: 3.8225 - val_mae: 3.8225\n",
      "Epoch 7/300\n",
      "12/12 [==============================] - 4s 298ms/step - loss: 3.8182 - mae: 3.8182 - val_loss: 3.7908 - val_mae: 3.7908\n",
      "Epoch 8/300\n",
      "12/12 [==============================] - 4s 298ms/step - loss: 3.7847 - mae: 3.7847 - val_loss: 3.7589 - val_mae: 3.7589\n",
      "Epoch 9/300\n",
      "12/12 [==============================] - 4s 292ms/step - loss: 3.7495 - mae: 3.7495 - val_loss: 3.7207 - val_mae: 3.7207\n",
      "Epoch 10/300\n",
      "12/12 [==============================] - 3s 284ms/step - loss: 3.7128 - mae: 3.7128 - val_loss: 3.6850 - val_mae: 3.6850\n",
      "Epoch 11/300\n",
      "12/12 [==============================] - 3s 287ms/step - loss: 3.6744 - mae: 3.6744 - val_loss: 3.6467 - val_mae: 3.6467\n",
      "Epoch 12/300\n",
      "12/12 [==============================] - 4s 290ms/step - loss: 3.6343 - mae: 3.6343 - val_loss: 3.6052 - val_mae: 3.6052\n",
      "Epoch 13/300\n",
      "12/12 [==============================] - 4s 292ms/step - loss: 3.5926 - mae: 3.5926 - val_loss: 3.5617 - val_mae: 3.5617\n",
      "Epoch 14/300\n",
      "12/12 [==============================] - 4s 293ms/step - loss: 3.5491 - mae: 3.5491 - val_loss: 3.5237 - val_mae: 3.5237\n",
      "Epoch 15/300\n",
      "12/12 [==============================] - 4s 293ms/step - loss: 3.5040 - mae: 3.5040 - val_loss: 3.4767 - val_mae: 3.4767\n",
      "Epoch 16/300\n",
      "12/12 [==============================] - 4s 294ms/step - loss: 3.4571 - mae: 3.4571 - val_loss: 3.4290 - val_mae: 3.4290\n",
      "Epoch 17/300\n",
      "12/12 [==============================] - 3s 277ms/step - loss: 3.4086 - mae: 3.4086 - val_loss: 3.3860 - val_mae: 3.3860\n",
      "Epoch 18/300\n",
      "12/12 [==============================] - 3s 277ms/step - loss: 3.3583 - mae: 3.3583 - val_loss: 3.3374 - val_mae: 3.3374\n",
      "Epoch 19/300\n",
      "12/12 [==============================] - 3s 274ms/step - loss: 3.3063 - mae: 3.3063 - val_loss: 3.2883 - val_mae: 3.2883\n",
      "Epoch 20/300\n",
      "12/12 [==============================] - 3s 277ms/step - loss: 3.2525 - mae: 3.2525 - val_loss: 3.2418 - val_mae: 3.2418\n",
      "Epoch 21/300\n",
      "12/12 [==============================] - 3s 276ms/step - loss: 3.1970 - mae: 3.1970 - val_loss: 3.1819 - val_mae: 3.1819\n",
      "Epoch 22/300\n",
      "12/12 [==============================] - 3s 273ms/step - loss: 3.1398 - mae: 3.1398 - val_loss: 3.1410 - val_mae: 3.1410\n",
      "Epoch 23/300\n",
      "12/12 [==============================] - 3s 275ms/step - loss: 3.0808 - mae: 3.0808 - val_loss: 3.0932 - val_mae: 3.0932\n",
      "Epoch 24/300\n",
      "12/12 [==============================] - 3s 273ms/step - loss: 3.0201 - mae: 3.0201 - val_loss: 3.0392 - val_mae: 3.0392\n",
      "Epoch 25/300\n",
      "12/12 [==============================] - 3s 276ms/step - loss: 2.9577 - mae: 2.9577 - val_loss: 2.9832 - val_mae: 2.9832\n",
      "Epoch 26/300\n",
      "12/12 [==============================] - 3s 273ms/step - loss: 2.8940 - mae: 2.8940 - val_loss: 2.5659 - val_mae: 2.5659\n",
      "Epoch 27/300\n",
      "12/12 [==============================] - 3s 277ms/step - loss: 2.8314 - mae: 2.8314 - val_loss: 2.2686 - val_mae: 2.2686\n",
      "Epoch 28/300\n",
      "12/12 [==============================] - 3s 276ms/step - loss: 2.7612 - mae: 2.7612 - val_loss: 2.3609 - val_mae: 2.3609\n",
      "Epoch 29/300\n",
      "12/12 [==============================] - 3s 277ms/step - loss: 2.6919 - mae: 2.6919 - val_loss: 2.4245 - val_mae: 2.4245\n",
      "Epoch 30/300\n",
      "12/12 [==============================] - 3s 279ms/step - loss: 2.6208 - mae: 2.6208 - val_loss: 2.3954 - val_mae: 2.3954\n",
      "Epoch 31/300\n",
      "12/12 [==============================] - 3s 279ms/step - loss: 2.5479 - mae: 2.5479 - val_loss: 2.3506 - val_mae: 2.3506\n",
      "Epoch 32/300\n",
      "12/12 [==============================] - 3s 275ms/step - loss: 2.4732 - mae: 2.4732 - val_loss: 2.2880 - val_mae: 2.2880\n",
      "Epoch 33/300\n",
      "12/12 [==============================] - 3s 278ms/step - loss: 2.3973 - mae: 2.3973 - val_loss: 2.1171 - val_mae: 2.1171\n",
      "Epoch 34/300\n",
      "12/12 [==============================] - 3s 281ms/step - loss: 2.3190 - mae: 2.3190 - val_loss: 1.9761 - val_mae: 1.9761\n",
      "Epoch 35/300\n",
      "12/12 [==============================] - 3s 278ms/step - loss: 2.2392 - mae: 2.2392 - val_loss: 1.8878 - val_mae: 1.8878\n",
      "Epoch 36/300\n",
      "12/12 [==============================] - 3s 288ms/step - loss: 2.1578 - mae: 2.1578 - val_loss: 1.9509 - val_mae: 1.9509\n",
      "Epoch 37/300\n",
      "12/12 [==============================] - 3s 286ms/step - loss: 2.0751 - mae: 2.0751 - val_loss: 1.8902 - val_mae: 1.8902\n",
      "Epoch 38/300\n",
      "12/12 [==============================] - 3s 280ms/step - loss: 1.9907 - mae: 1.9907 - val_loss: 1.6567 - val_mae: 1.6567\n",
      "Epoch 39/300\n",
      "12/12 [==============================] - 3s 281ms/step - loss: 1.9061 - mae: 1.9061 - val_loss: 1.5102 - val_mae: 1.5102\n",
      "Epoch 40/300\n",
      "12/12 [==============================] - 3s 280ms/step - loss: 1.8193 - mae: 1.8193 - val_loss: 1.5017 - val_mae: 1.5017\n",
      "Epoch 41/300\n",
      "12/12 [==============================] - 3s 282ms/step - loss: 1.7311 - mae: 1.7311 - val_loss: 1.3184 - val_mae: 1.3184\n",
      "Epoch 42/300\n",
      "12/12 [==============================] - 3s 286ms/step - loss: 1.6416 - mae: 1.6416 - val_loss: 1.3534 - val_mae: 1.3534\n",
      "Epoch 43/300\n",
      "12/12 [==============================] - 3s 283ms/step - loss: 1.5510 - mae: 1.5510 - val_loss: 1.1721 - val_mae: 1.1721\n",
      "Epoch 44/300\n",
      "12/12 [==============================] - 3s 282ms/step - loss: 1.4592 - mae: 1.4592 - val_loss: 1.0338 - val_mae: 1.0338\n",
      "Epoch 45/300\n",
      "12/12 [==============================] - 3s 284ms/step - loss: 1.3738 - mae: 1.3738 - val_loss: 1.1128 - val_mae: 1.1128\n",
      "Epoch 46/300\n",
      "12/12 [==============================] - 3s 283ms/step - loss: 1.2816 - mae: 1.2816 - val_loss: 1.0272 - val_mae: 1.0272\n",
      "Epoch 47/300\n",
      "12/12 [==============================] - 3s 287ms/step - loss: 1.1926 - mae: 1.1926 - val_loss: 0.9913 - val_mae: 0.9913\n",
      "Epoch 48/300\n",
      "12/12 [==============================] - 3s 287ms/step - loss: 1.1116 - mae: 1.1116 - val_loss: 1.0254 - val_mae: 1.0254\n",
      "Epoch 49/300\n",
      "12/12 [==============================] - 3s 290ms/step - loss: 1.0184 - mae: 1.0184 - val_loss: 1.0701 - val_mae: 1.0701\n",
      "Epoch 50/300\n",
      "12/12 [==============================] - 3s 280ms/step - loss: 0.9332 - mae: 0.9332 - val_loss: 0.9386 - val_mae: 0.9386\n",
      "Epoch 51/300\n",
      "12/12 [==============================] - 3s 278ms/step - loss: 0.8475 - mae: 0.8475 - val_loss: 0.8947 - val_mae: 0.8947\n",
      "Epoch 52/300\n",
      "12/12 [==============================] - 3s 280ms/step - loss: 0.7669 - mae: 0.7669 - val_loss: 0.9229 - val_mae: 0.9229\n",
      "Epoch 53/300\n",
      "12/12 [==============================] - 3s 280ms/step - loss: 0.6897 - mae: 0.6897 - val_loss: 0.8770 - val_mae: 0.8770\n",
      "Epoch 54/300\n",
      "12/12 [==============================] - 3s 281ms/step - loss: 0.6279 - mae: 0.6279 - val_loss: 0.8748 - val_mae: 0.8748\n",
      "Epoch 55/300\n",
      "12/12 [==============================] - 3s 283ms/step - loss: 0.5669 - mae: 0.5669 - val_loss: 0.9268 - val_mae: 0.9268\n",
      "Epoch 56/300\n",
      "12/12 [==============================] - 3s 280ms/step - loss: 0.5130 - mae: 0.5130 - val_loss: 0.9145 - val_mae: 0.9145\n",
      "Epoch 57/300\n",
      "12/12 [==============================] - 3s 279ms/step - loss: 0.4444 - mae: 0.4444 - val_loss: 1.0142 - val_mae: 1.0142\n",
      "Epoch 58/300\n",
      "12/12 [==============================] - 3s 282ms/step - loss: 0.4296 - mae: 0.4296 - val_loss: 0.9915 - val_mae: 0.9915\n",
      "Epoch 59/300\n",
      "12/12 [==============================] - 3s 281ms/step - loss: 0.3787 - mae: 0.3787 - val_loss: 1.1041 - val_mae: 1.1041\n",
      "Epoch 60/300\n",
      "12/12 [==============================] - 3s 283ms/step - loss: 0.3604 - mae: 0.3604 - val_loss: 0.7970 - val_mae: 0.7970\n",
      "Epoch 61/300\n",
      "12/12 [==============================] - 3s 284ms/step - loss: 0.3215 - mae: 0.3215 - val_loss: 0.9753 - val_mae: 0.9753\n",
      "Epoch 62/300\n",
      "12/12 [==============================] - 3s 285ms/step - loss: 0.2893 - mae: 0.2893 - val_loss: 1.0084 - val_mae: 1.0084\n",
      "Epoch 63/300\n",
      "12/12 [==============================] - 3s 285ms/step - loss: 0.2927 - mae: 0.2927 - val_loss: 1.3401 - val_mae: 1.3401\n",
      "Epoch 64/300\n",
      "12/12 [==============================] - 3s 287ms/step - loss: 0.2651 - mae: 0.2651 - val_loss: 1.6297 - val_mae: 1.6297\n",
      "Epoch 65/300\n",
      "12/12 [==============================] - 3s 283ms/step - loss: 0.2612 - mae: 0.2612 - val_loss: 1.2103 - val_mae: 1.2103\n",
      "Epoch 66/300\n",
      "12/12 [==============================] - 3s 284ms/step - loss: 0.2181 - mae: 0.2181 - val_loss: 1.0817 - val_mae: 1.0817\n",
      "Epoch 67/300\n",
      "12/12 [==============================] - 3s 286ms/step - loss: 0.2145 - mae: 0.2145 - val_loss: 0.8254 - val_mae: 0.8254\n",
      "Epoch 68/300\n",
      "12/12 [==============================] - 3s 284ms/step - loss: 0.2309 - mae: 0.2309 - val_loss: 0.8693 - val_mae: 0.8693\n",
      "Epoch 69/300\n",
      "12/12 [==============================] - 3s 284ms/step - loss: 0.1821 - mae: 0.1821 - val_loss: 0.7767 - val_mae: 0.7767\n",
      "Epoch 70/300\n",
      "12/12 [==============================] - 3s 283ms/step - loss: 0.2130 - mae: 0.2130 - val_loss: 0.7753 - val_mae: 0.7753\n",
      "Epoch 71/300\n",
      "12/12 [==============================] - 3s 283ms/step - loss: 0.2012 - mae: 0.2012 - val_loss: 0.7388 - val_mae: 0.7388\n",
      "Epoch 72/300\n",
      "12/12 [==============================] - 3s 287ms/step - loss: 0.1879 - mae: 0.1879 - val_loss: 0.7404 - val_mae: 0.7404\n",
      "Epoch 73/300\n",
      "12/12 [==============================] - 3s 285ms/step - loss: 0.1647 - mae: 0.1647 - val_loss: 0.7669 - val_mae: 0.7669\n",
      "Epoch 74/300\n",
      "12/12 [==============================] - 3s 285ms/step - loss: 0.1566 - mae: 0.1566 - val_loss: 0.7957 - val_mae: 0.7957\n",
      "Epoch 75/300\n",
      "12/12 [==============================] - 3s 283ms/step - loss: 0.1845 - mae: 0.1845 - val_loss: 0.7218 - val_mae: 0.7218\n",
      "Epoch 76/300\n",
      "12/12 [==============================] - 3s 290ms/step - loss: 0.1567 - mae: 0.1567 - val_loss: 0.8030 - val_mae: 0.8030\n",
      "Epoch 77/300\n",
      "12/12 [==============================] - 3s 284ms/step - loss: 0.1883 - mae: 0.1883 - val_loss: 0.8046 - val_mae: 0.8046\n",
      "Epoch 78/300\n",
      "12/12 [==============================] - 4s 293ms/step - loss: 0.1573 - mae: 0.1573 - val_loss: 0.7632 - val_mae: 0.7632\n",
      "Epoch 79/300\n",
      "12/12 [==============================] - 3s 290ms/step - loss: 0.1480 - mae: 0.1480 - val_loss: 0.7727 - val_mae: 0.7727\n",
      "Epoch 80/300\n",
      "12/12 [==============================] - 3s 286ms/step - loss: 0.1424 - mae: 0.1424 - val_loss: 0.7486 - val_mae: 0.7486\n",
      "Epoch 81/300\n",
      "12/12 [==============================] - 4s 294ms/step - loss: 0.1273 - mae: 0.1273 - val_loss: 0.7365 - val_mae: 0.7365\n",
      "Epoch 82/300\n",
      "12/12 [==============================] - 3s 287ms/step - loss: 0.1350 - mae: 0.1350 - val_loss: 0.7567 - val_mae: 0.7567\n",
      "Epoch 83/300\n",
      "12/12 [==============================] - 4s 291ms/step - loss: 0.1612 - mae: 0.1612 - val_loss: 0.7487 - val_mae: 0.7487\n",
      "Epoch 84/300\n",
      "12/12 [==============================] - 3s 286ms/step - loss: 0.1170 - mae: 0.1170 - val_loss: 0.7442 - val_mae: 0.7442\n",
      "Epoch 85/300\n",
      "12/12 [==============================] - 4s 291ms/step - loss: 0.1401 - mae: 0.1401 - val_loss: 0.7178 - val_mae: 0.7178\n",
      "Epoch 86/300\n",
      "12/12 [==============================] - 3s 289ms/step - loss: 0.1580 - mae: 0.1580 - val_loss: 0.7426 - val_mae: 0.7426\n",
      "Epoch 87/300\n",
      "12/12 [==============================] - 3s 289ms/step - loss: 0.1463 - mae: 0.1463 - val_loss: 0.7576 - val_mae: 0.7576\n",
      "Epoch 88/300\n",
      "12/12 [==============================] - 4s 293ms/step - loss: 0.1244 - mae: 0.1244 - val_loss: 0.7926 - val_mae: 0.7926\n",
      "Epoch 89/300\n",
      "12/12 [==============================] - 3s 289ms/step - loss: 0.1343 - mae: 0.1343 - val_loss: 0.7677 - val_mae: 0.7677\n",
      "Epoch 90/300\n",
      "12/12 [==============================] - 4s 292ms/step - loss: 0.1143 - mae: 0.1143 - val_loss: 0.7562 - val_mae: 0.7562\n",
      "Epoch 91/300\n",
      "12/12 [==============================] - 3s 290ms/step - loss: 0.1301 - mae: 0.1301 - val_loss: 0.7212 - val_mae: 0.7212\n",
      "Epoch 92/300\n",
      "12/12 [==============================] - 4s 296ms/step - loss: 0.1190 - mae: 0.1190 - val_loss: 0.7301 - val_mae: 0.7301\n",
      "Epoch 93/300\n",
      "12/12 [==============================] - 4s 294ms/step - loss: 0.1545 - mae: 0.1545 - val_loss: 0.7299 - val_mae: 0.7299\n",
      "Epoch 94/300\n",
      "12/12 [==============================] - 4s 291ms/step - loss: 0.1169 - mae: 0.1169 - val_loss: 0.7292 - val_mae: 0.7292\n",
      "Epoch 95/300\n",
      "12/12 [==============================] - 4s 291ms/step - loss: 0.0942 - mae: 0.0942 - val_loss: 0.7248 - val_mae: 0.7248\n",
      "Epoch 96/300\n",
      "12/12 [==============================] - 4s 293ms/step - loss: 0.1259 - mae: 0.1259 - val_loss: 0.7658 - val_mae: 0.7658\n",
      "Epoch 97/300\n",
      "12/12 [==============================] - 4s 291ms/step - loss: 0.1460 - mae: 0.1460 - val_loss: 0.7233 - val_mae: 0.7233\n",
      "Epoch 98/300\n",
      "12/12 [==============================] - 4s 291ms/step - loss: 0.1195 - mae: 0.1195 - val_loss: 0.7312 - val_mae: 0.7312\n",
      "Epoch 99/300\n",
      "12/12 [==============================] - 4s 291ms/step - loss: 0.1243 - mae: 0.1243 - val_loss: 0.7379 - val_mae: 0.7379\n",
      "Epoch 100/300\n",
      "12/12 [==============================] - 3s 290ms/step - loss: 0.0997 - mae: 0.0997 - val_loss: 0.7412 - val_mae: 0.7412\n",
      "Epoch 101/300\n",
      "12/12 [==============================] - 3s 289ms/step - loss: 0.1521 - mae: 0.1521 - val_loss: 0.8197 - val_mae: 0.8197\n",
      "Epoch 102/300\n",
      "12/12 [==============================] - 3s 290ms/step - loss: 0.1041 - mae: 0.1041 - val_loss: 0.7442 - val_mae: 0.7442\n",
      "Epoch 103/300\n",
      "12/12 [==============================] - 3s 290ms/step - loss: 0.1221 - mae: 0.1221 - val_loss: 0.7299 - val_mae: 0.7299\n",
      "Epoch 104/300\n",
      "12/12 [==============================] - 3s 287ms/step - loss: 0.1429 - mae: 0.1429 - val_loss: 0.7336 - val_mae: 0.7336\n",
      "Epoch 105/300\n",
      "12/12 [==============================] - 3s 287ms/step - loss: 0.1120 - mae: 0.1120 - val_loss: 0.7299 - val_mae: 0.7299\n",
      "Epoch 106/300\n",
      "12/12 [==============================] - 3s 288ms/step - loss: 0.1156 - mae: 0.1156 - val_loss: 0.7426 - val_mae: 0.7426\n",
      "Epoch 107/300\n",
      "12/12 [==============================] - 4s 291ms/step - loss: 0.1338 - mae: 0.1338 - val_loss: 0.7284 - val_mae: 0.7284\n",
      "Epoch 108/300\n",
      "12/12 [==============================] - 3s 289ms/step - loss: 0.1246 - mae: 0.1246 - val_loss: 0.7279 - val_mae: 0.7279\n",
      "Epoch 109/300\n",
      "12/12 [==============================] - 3s 288ms/step - loss: 0.1196 - mae: 0.1196 - val_loss: 0.7525 - val_mae: 0.7525\n",
      "Epoch 110/300\n",
      "12/12 [==============================] - 3s 290ms/step - loss: 0.1506 - mae: 0.1506 - val_loss: 0.7236 - val_mae: 0.7236\n",
      "Epoch 111/300\n",
      "12/12 [==============================] - 3s 289ms/step - loss: 0.1490 - mae: 0.1490 - val_loss: 0.7597 - val_mae: 0.7597\n",
      "Epoch 112/300\n",
      "12/12 [==============================] - 3s 286ms/step - loss: 0.1189 - mae: 0.1189 - val_loss: 0.7462 - val_mae: 0.7462\n",
      "Epoch 113/300\n",
      "12/12 [==============================] - 3s 287ms/step - loss: 0.1480 - mae: 0.1480 - val_loss: 0.7311 - val_mae: 0.7311\n",
      "Epoch 114/300\n",
      "12/12 [==============================] - 3s 288ms/step - loss: 0.1139 - mae: 0.1139 - val_loss: 0.7420 - val_mae: 0.7420\n",
      "Epoch 115/300\n",
      "12/12 [==============================] - 3s 287ms/step - loss: 0.1096 - mae: 0.1096 - val_loss: 0.7279 - val_mae: 0.7279\n",
      "Epoch 116/300\n",
      "12/12 [==============================] - 4s 300ms/step - loss: 0.1208 - mae: 0.1208 - val_loss: 0.7284 - val_mae: 0.7284\n",
      "Epoch 117/300\n",
      "12/12 [==============================] - 4s 311ms/step - loss: 0.1220 - mae: 0.1220 - val_loss: 0.7472 - val_mae: 0.7472\n",
      "Epoch 118/300\n",
      "12/12 [==============================] - 4s 309ms/step - loss: 0.1370 - mae: 0.1370 - val_loss: 0.7461 - val_mae: 0.7461\n",
      "Epoch 119/300\n",
      "12/12 [==============================] - 4s 300ms/step - loss: 0.1230 - mae: 0.1230 - val_loss: 0.7212 - val_mae: 0.7212\n",
      "Epoch 120/300\n",
      "12/12 [==============================] - 3s 289ms/step - loss: 0.1077 - mae: 0.1077 - val_loss: 0.7414 - val_mae: 0.7414\n",
      "Epoch 121/300\n",
      "12/12 [==============================] - 3s 288ms/step - loss: 0.1365 - mae: 0.1365 - val_loss: 0.7244 - val_mae: 0.7244\n",
      "Epoch 122/300\n",
      "12/12 [==============================] - 3s 290ms/step - loss: 0.1255 - mae: 0.1255 - val_loss: 0.7331 - val_mae: 0.7331\n",
      "Epoch 123/300\n",
      "12/12 [==============================] - 3s 289ms/step - loss: 0.1248 - mae: 0.1248 - val_loss: 0.7317 - val_mae: 0.7317\n",
      "Epoch 124/300\n",
      "12/12 [==============================] - 4s 290ms/step - loss: 0.1105 - mae: 0.1105 - val_loss: 0.7296 - val_mae: 0.7296\n",
      "Epoch 125/300\n",
      "12/12 [==============================] - 4s 293ms/step - loss: 0.1290 - mae: 0.1290 - val_loss: 0.7368 - val_mae: 0.7368\n",
      "Epoch 126/300\n",
      "12/12 [==============================] - 3s 289ms/step - loss: 0.1293 - mae: 0.1293 - val_loss: 0.7906 - val_mae: 0.7906\n",
      "Epoch 127/300\n",
      "12/12 [==============================] - 4s 295ms/step - loss: 0.1004 - mae: 0.1004 - val_loss: 0.7594 - val_mae: 0.7594\n",
      "Epoch 128/300\n",
      "12/12 [==============================] - 3s 288ms/step - loss: 0.1154 - mae: 0.1154 - val_loss: 0.7237 - val_mae: 0.7237\n",
      "Epoch 129/300\n",
      "12/12 [==============================] - 4s 297ms/step - loss: 0.1455 - mae: 0.1455 - val_loss: 0.7226 - val_mae: 0.7226\n",
      "Epoch 130/300\n",
      "12/12 [==============================] - 4s 294ms/step - loss: 0.1533 - mae: 0.1533 - val_loss: 0.7245 - val_mae: 0.7245\n",
      "Epoch 131/300\n",
      "12/12 [==============================] - 4s 293ms/step - loss: 0.1351 - mae: 0.1351 - val_loss: 0.7279 - val_mae: 0.7279\n",
      "Epoch 132/300\n",
      "12/12 [==============================] - 3s 286ms/step - loss: 0.1061 - mae: 0.1061 - val_loss: 0.7277 - val_mae: 0.7277\n",
      "Epoch 133/300\n",
      "12/12 [==============================] - 3s 289ms/step - loss: 0.0993 - mae: 0.0993 - val_loss: 0.7374 - val_mae: 0.7374\n",
      "Epoch 134/300\n",
      "12/12 [==============================] - 3s 286ms/step - loss: 0.1384 - mae: 0.1384 - val_loss: 0.7177 - val_mae: 0.7177\n",
      "Epoch 135/300\n",
      "12/12 [==============================] - 4s 294ms/step - loss: 0.1117 - mae: 0.1117 - val_loss: 0.7282 - val_mae: 0.7282\n",
      "Epoch 136/300\n",
      "12/12 [==============================] - 3s 286ms/step - loss: 0.1379 - mae: 0.1379 - val_loss: 0.7392 - val_mae: 0.7392\n",
      "Epoch 137/300\n",
      "12/12 [==============================] - 3s 287ms/step - loss: 0.1264 - mae: 0.1264 - val_loss: 0.7572 - val_mae: 0.7572\n",
      "Epoch 138/300\n",
      "12/12 [==============================] - 3s 289ms/step - loss: 0.1237 - mae: 0.1237 - val_loss: 0.7647 - val_mae: 0.7647\n",
      "Epoch 139/300\n",
      "12/12 [==============================] - 3s 287ms/step - loss: 0.1187 - mae: 0.1187 - val_loss: 0.7288 - val_mae: 0.7288\n",
      "Epoch 140/300\n",
      "12/12 [==============================] - 3s 288ms/step - loss: 0.1008 - mae: 0.1008 - val_loss: 0.7527 - val_mae: 0.7527\n",
      "Epoch 141/300\n",
      "12/12 [==============================] - 3s 291ms/step - loss: 0.1124 - mae: 0.1124 - val_loss: 0.7327 - val_mae: 0.7327\n",
      "Epoch 142/300\n",
      "12/12 [==============================] - 3s 291ms/step - loss: 0.1488 - mae: 0.1488 - val_loss: 0.7412 - val_mae: 0.7412\n",
      "Epoch 143/300\n",
      "12/12 [==============================] - 3s 287ms/step - loss: 0.1415 - mae: 0.1415 - val_loss: 0.7284 - val_mae: 0.7284\n",
      "Epoch 144/300\n",
      "12/12 [==============================] - 3s 288ms/step - loss: 0.1527 - mae: 0.1527 - val_loss: 0.7361 - val_mae: 0.7361\n",
      "Epoch 145/300\n",
      "12/12 [==============================] - 3s 289ms/step - loss: 0.1580 - mae: 0.1580 - val_loss: 0.7823 - val_mae: 0.7823\n",
      "Epoch 146/300\n",
      "12/12 [==============================] - 3s 287ms/step - loss: 0.1371 - mae: 0.1371 - val_loss: 0.7600 - val_mae: 0.7600\n",
      "Epoch 147/300\n",
      "12/12 [==============================] - 3s 287ms/step - loss: 0.1170 - mae: 0.1170 - val_loss: 0.7362 - val_mae: 0.7362\n",
      "Epoch 148/300\n",
      "12/12 [==============================] - 3s 291ms/step - loss: 0.0947 - mae: 0.0947 - val_loss: 0.7245 - val_mae: 0.7245\n",
      "Epoch 149/300\n",
      "12/12 [==============================] - 3s 286ms/step - loss: 0.0946 - mae: 0.0946 - val_loss: 0.7248 - val_mae: 0.7248\n",
      "Epoch 150/300\n",
      "12/12 [==============================] - 3s 287ms/step - loss: 0.1383 - mae: 0.1383 - val_loss: 0.7197 - val_mae: 0.7197\n",
      "Epoch 151/300\n",
      "12/12 [==============================] - 3s 288ms/step - loss: 0.1267 - mae: 0.1267 - val_loss: 0.7513 - val_mae: 0.7513\n",
      "Epoch 152/300\n",
      "12/12 [==============================] - 3s 289ms/step - loss: 0.1049 - mae: 0.1049 - val_loss: 0.7487 - val_mae: 0.7487\n",
      "Epoch 153/300\n",
      "12/12 [==============================] - 3s 285ms/step - loss: 0.1032 - mae: 0.1032 - val_loss: 0.7238 - val_mae: 0.7238\n",
      "Epoch 154/300\n",
      "12/12 [==============================] - 3s 287ms/step - loss: 0.1591 - mae: 0.1591 - val_loss: 0.7637 - val_mae: 0.7637\n",
      "Epoch 155/300\n",
      "12/12 [==============================] - 3s 286ms/step - loss: 0.1151 - mae: 0.1151 - val_loss: 0.7200 - val_mae: 0.7200\n",
      "Epoch 156/300\n",
      "12/12 [==============================] - 3s 290ms/step - loss: 0.1520 - mae: 0.1520 - val_loss: 0.7259 - val_mae: 0.7259\n",
      "Epoch 157/300\n",
      "12/12 [==============================] - 3s 289ms/step - loss: 0.1319 - mae: 0.1319 - val_loss: 0.7207 - val_mae: 0.7207\n",
      "Epoch 158/300\n",
      "12/12 [==============================] - 3s 288ms/step - loss: 0.1367 - mae: 0.1367 - val_loss: 0.7358 - val_mae: 0.7358\n",
      "Epoch 159/300\n",
      "12/12 [==============================] - 3s 289ms/step - loss: 0.1154 - mae: 0.1154 - val_loss: 0.7193 - val_mae: 0.7193\n",
      "Epoch 160/300\n",
      "12/12 [==============================] - 3s 290ms/step - loss: 0.1155 - mae: 0.1155 - val_loss: 0.7229 - val_mae: 0.7229\n",
      "Epoch 161/300\n",
      "12/12 [==============================] - 3s 287ms/step - loss: 0.0913 - mae: 0.0913 - val_loss: 0.7220 - val_mae: 0.7220\n",
      "Epoch 162/300\n",
      "12/12 [==============================] - 3s 288ms/step - loss: 0.1682 - mae: 0.1682 - val_loss: 0.7285 - val_mae: 0.7285\n",
      "Epoch 163/300\n",
      "12/12 [==============================] - 3s 289ms/step - loss: 0.1377 - mae: 0.1377 - val_loss: 0.7213 - val_mae: 0.7213\n",
      "Epoch 164/300\n",
      "12/12 [==============================] - 3s 288ms/step - loss: 0.0877 - mae: 0.0877 - val_loss: 0.7595 - val_mae: 0.7595\n",
      "Epoch 165/300\n",
      "12/12 [==============================] - 3s 288ms/step - loss: 0.0875 - mae: 0.0875 - val_loss: 0.7343 - val_mae: 0.7343\n",
      "Epoch 166/300\n",
      "12/12 [==============================] - 4s 290ms/step - loss: 0.1042 - mae: 0.1042 - val_loss: 0.7217 - val_mae: 0.7217\n",
      "Epoch 167/300\n",
      "12/12 [==============================] - 3s 290ms/step - loss: 0.1137 - mae: 0.1137 - val_loss: 0.7442 - val_mae: 0.7442\n",
      "Epoch 168/300\n",
      "12/12 [==============================] - 3s 290ms/step - loss: 0.1303 - mae: 0.1303 - val_loss: 0.7478 - val_mae: 0.7478\n",
      "Epoch 169/300\n",
      "12/12 [==============================] - 3s 285ms/step - loss: 0.1195 - mae: 0.1195 - val_loss: 0.7965 - val_mae: 0.7965\n",
      "Epoch 170/300\n",
      "12/12 [==============================] - 3s 290ms/step - loss: 0.0974 - mae: 0.0974 - val_loss: 0.7199 - val_mae: 0.7199\n",
      "Epoch 171/300\n",
      "12/12 [==============================] - 3s 285ms/step - loss: 0.1103 - mae: 0.1103 - val_loss: 0.7266 - val_mae: 0.7266\n",
      "Epoch 172/300\n",
      "12/12 [==============================] - 3s 289ms/step - loss: 0.1062 - mae: 0.1062 - val_loss: 0.7700 - val_mae: 0.7700\n",
      "Epoch 173/300\n",
      "12/12 [==============================] - 3s 284ms/step - loss: 0.1248 - mae: 0.1248 - val_loss: 0.7257 - val_mae: 0.7257\n",
      "Epoch 174/300\n",
      "12/12 [==============================] - 3s 291ms/step - loss: 0.0914 - mae: 0.0914 - val_loss: 0.7332 - val_mae: 0.7332\n",
      "Epoch 175/300\n",
      "12/12 [==============================] - 3s 286ms/step - loss: 0.1213 - mae: 0.1213 - val_loss: 0.7232 - val_mae: 0.7232\n",
      "Epoch 176/300\n",
      "12/12 [==============================] - 3s 285ms/step - loss: 0.1175 - mae: 0.1175 - val_loss: 0.7912 - val_mae: 0.7912\n",
      "Epoch 177/300\n",
      "12/12 [==============================] - 3s 289ms/step - loss: 0.1032 - mae: 0.1032 - val_loss: 0.7454 - val_mae: 0.7454\n",
      "Epoch 178/300\n",
      "12/12 [==============================] - 3s 286ms/step - loss: 0.1171 - mae: 0.1171 - val_loss: 0.7319 - val_mae: 0.7319\n",
      "Epoch 179/300\n",
      "12/12 [==============================] - 3s 288ms/step - loss: 0.1559 - mae: 0.1559 - val_loss: 0.7370 - val_mae: 0.7370\n",
      "Epoch 180/300\n",
      "12/12 [==============================] - 3s 287ms/step - loss: 0.1017 - mae: 0.1017 - val_loss: 0.7753 - val_mae: 0.7753\n",
      "Epoch 181/300\n",
      "12/12 [==============================] - 3s 291ms/step - loss: 0.1067 - mae: 0.1067 - val_loss: 0.7260 - val_mae: 0.7260\n",
      "Epoch 182/300\n",
      "12/12 [==============================] - 3s 285ms/step - loss: 0.0853 - mae: 0.0853 - val_loss: 0.7328 - val_mae: 0.7328\n",
      "Epoch 183/300\n",
      "12/12 [==============================] - 3s 287ms/step - loss: 0.0955 - mae: 0.0955 - val_loss: 0.7226 - val_mae: 0.7226\n",
      "Epoch 184/300\n",
      "12/12 [==============================] - 3s 289ms/step - loss: 0.1052 - mae: 0.1052 - val_loss: 0.7284 - val_mae: 0.7284\n",
      "Epoch 185/300\n",
      "12/12 [==============================] - 3s 289ms/step - loss: 0.1193 - mae: 0.1193 - val_loss: 0.8094 - val_mae: 0.8094\n",
      "Epoch 186/300\n",
      "12/12 [==============================] - 3s 286ms/step - loss: 0.1755 - mae: 0.1755 - val_loss: 0.7543 - val_mae: 0.7543\n",
      "Epoch 187/300\n",
      "12/12 [==============================] - 3s 288ms/step - loss: 0.1331 - mae: 0.1331 - val_loss: 0.7312 - val_mae: 0.7312\n",
      "Epoch 188/300\n",
      "12/12 [==============================] - 3s 289ms/step - loss: 0.1276 - mae: 0.1276 - val_loss: 0.7307 - val_mae: 0.7307\n",
      "Epoch 189/300\n",
      "12/12 [==============================] - 3s 287ms/step - loss: 0.1139 - mae: 0.1139 - val_loss: 0.7306 - val_mae: 0.7306\n",
      "Epoch 190/300\n",
      "12/12 [==============================] - 3s 289ms/step - loss: 0.1277 - mae: 0.1277 - val_loss: 0.7336 - val_mae: 0.7336\n",
      "Epoch 191/300\n",
      "12/12 [==============================] - 3s 287ms/step - loss: 0.1239 - mae: 0.1239 - val_loss: 0.7190 - val_mae: 0.7190\n",
      "Epoch 192/300\n",
      "12/12 [==============================] - 3s 289ms/step - loss: 0.1198 - mae: 0.1198 - val_loss: 0.7231 - val_mae: 0.7231\n",
      "Epoch 193/300\n",
      "12/12 [==============================] - 3s 286ms/step - loss: 0.1111 - mae: 0.1111 - val_loss: 0.7328 - val_mae: 0.7328\n",
      "Epoch 194/300\n",
      "12/12 [==============================] - 3s 289ms/step - loss: 0.1026 - mae: 0.1026 - val_loss: 0.7214 - val_mae: 0.7214\n",
      "Epoch 195/300\n",
      "12/12 [==============================] - 3s 286ms/step - loss: 0.0992 - mae: 0.0992 - val_loss: 0.7463 - val_mae: 0.7463\n",
      "Epoch 196/300\n",
      "12/12 [==============================] - 4s 291ms/step - loss: 0.1063 - mae: 0.1063 - val_loss: 0.7269 - val_mae: 0.7269\n",
      "Epoch 197/300\n",
      "12/12 [==============================] - 3s 288ms/step - loss: 0.1305 - mae: 0.1305 - val_loss: 0.7400 - val_mae: 0.7400\n",
      "Epoch 198/300\n",
      "12/12 [==============================] - 3s 286ms/step - loss: 0.1108 - mae: 0.1108 - val_loss: 0.7351 - val_mae: 0.7351\n",
      "Epoch 199/300\n",
      "12/12 [==============================] - 3s 284ms/step - loss: 0.1351 - mae: 0.1351 - val_loss: 0.7259 - val_mae: 0.7259\n",
      "Epoch 200/300\n",
      "12/12 [==============================] - 3s 289ms/step - loss: 0.1278 - mae: 0.1278 - val_loss: 0.7373 - val_mae: 0.7373\n",
      "Epoch 201/300\n",
      "12/12 [==============================] - 3s 288ms/step - loss: 0.0946 - mae: 0.0946 - val_loss: 0.7340 - val_mae: 0.7340\n",
      "Epoch 202/300\n",
      "12/12 [==============================] - 3s 290ms/step - loss: 0.1231 - mae: 0.1231 - val_loss: 0.7451 - val_mae: 0.7451\n",
      "Epoch 203/300\n",
      "12/12 [==============================] - 3s 288ms/step - loss: 0.1041 - mae: 0.1041 - val_loss: 0.7287 - val_mae: 0.7287\n",
      "Epoch 204/300\n",
      "12/12 [==============================] - 4s 294ms/step - loss: 0.1001 - mae: 0.1001 - val_loss: 0.7349 - val_mae: 0.7349\n",
      "Epoch 205/300\n",
      "12/12 [==============================] - 3s 288ms/step - loss: 0.1253 - mae: 0.1253 - val_loss: 0.7283 - val_mae: 0.7283\n",
      "Epoch 206/300\n",
      "12/12 [==============================] - 3s 286ms/step - loss: 0.1308 - mae: 0.1308 - val_loss: 0.7226 - val_mae: 0.7226\n",
      "Epoch 207/300\n",
      "12/12 [==============================] - 3s 289ms/step - loss: 0.1164 - mae: 0.1164 - val_loss: 0.7426 - val_mae: 0.7426\n",
      "Epoch 208/300\n",
      "12/12 [==============================] - 4s 292ms/step - loss: 0.1211 - mae: 0.1211 - val_loss: 0.9314 - val_mae: 0.9314\n",
      "Epoch 209/300\n",
      "12/12 [==============================] - 3s 290ms/step - loss: 0.1430 - mae: 0.1430 - val_loss: 0.7235 - val_mae: 0.7235\n",
      "Epoch 210/300\n",
      "12/12 [==============================] - 4s 298ms/step - loss: 0.1411 - mae: 0.1411 - val_loss: 0.7289 - val_mae: 0.7289\n",
      "Epoch 211/300\n",
      "12/12 [==============================] - 4s 292ms/step - loss: 0.1049 - mae: 0.1049 - val_loss: 0.7425 - val_mae: 0.7425\n",
      "Epoch 212/300\n",
      "12/12 [==============================] - 4s 304ms/step - loss: 0.1172 - mae: 0.1172 - val_loss: 0.7259 - val_mae: 0.7259\n",
      "Epoch 213/300\n",
      "12/12 [==============================] - 4s 295ms/step - loss: 0.1161 - mae: 0.1161 - val_loss: 0.7343 - val_mae: 0.7343\n",
      "Epoch 214/300\n",
      "12/12 [==============================] - 3s 290ms/step - loss: 0.1047 - mae: 0.1047 - val_loss: 0.7291 - val_mae: 0.7291\n",
      "Epoch 215/300\n",
      "12/12 [==============================] - 4s 291ms/step - loss: 0.1098 - mae: 0.1098 - val_loss: 0.7351 - val_mae: 0.7351\n",
      "Epoch 216/300\n",
      "12/12 [==============================] - 3s 287ms/step - loss: 0.1134 - mae: 0.1134 - val_loss: 0.7222 - val_mae: 0.7222\n",
      "Epoch 217/300\n",
      "12/12 [==============================] - 3s 287ms/step - loss: 0.1245 - mae: 0.1245 - val_loss: 0.7202 - val_mae: 0.7202\n",
      "Epoch 218/300\n",
      "12/12 [==============================] - 3s 288ms/step - loss: 0.1245 - mae: 0.1245 - val_loss: 0.7410 - val_mae: 0.7410\n",
      "Epoch 219/300\n",
      "12/12 [==============================] - 4s 295ms/step - loss: 0.1044 - mae: 0.1044 - val_loss: 0.7257 - val_mae: 0.7257\n",
      "Epoch 220/300\n",
      "12/12 [==============================] - 4s 292ms/step - loss: 0.1348 - mae: 0.1348 - val_loss: 0.7407 - val_mae: 0.7407\n",
      "Epoch 221/300\n",
      "12/12 [==============================] - 3s 289ms/step - loss: 0.1299 - mae: 0.1299 - val_loss: 0.7274 - val_mae: 0.7274\n",
      "Epoch 222/300\n",
      "12/12 [==============================] - 3s 290ms/step - loss: 0.1307 - mae: 0.1307 - val_loss: 0.7247 - val_mae: 0.7247\n",
      "Epoch 223/300\n",
      "12/12 [==============================] - 3s 288ms/step - loss: 0.1117 - mae: 0.1117 - val_loss: 0.7222 - val_mae: 0.7222\n",
      "Epoch 224/300\n",
      "12/12 [==============================] - 4s 291ms/step - loss: 0.1343 - mae: 0.1343 - val_loss: 0.7367 - val_mae: 0.7367\n",
      "Epoch 225/300\n",
      "12/12 [==============================] - 3s 291ms/step - loss: 0.1225 - mae: 0.1225 - val_loss: 0.7311 - val_mae: 0.7311\n",
      "Epoch 226/300\n",
      "12/12 [==============================] - 4s 292ms/step - loss: 0.1584 - mae: 0.1584 - val_loss: 0.7374 - val_mae: 0.7374\n",
      "Epoch 227/300\n",
      "12/12 [==============================] - 3s 290ms/step - loss: 0.1194 - mae: 0.1194 - val_loss: 0.7396 - val_mae: 0.7396\n",
      "Epoch 228/300\n",
      "12/12 [==============================] - 3s 288ms/step - loss: 0.1708 - mae: 0.1708 - val_loss: 0.7367 - val_mae: 0.7367\n",
      "Epoch 229/300\n",
      "12/12 [==============================] - 3s 287ms/step - loss: 0.1220 - mae: 0.1220 - val_loss: 0.7242 - val_mae: 0.7242\n",
      "Epoch 230/300\n",
      "12/12 [==============================] - 3s 288ms/step - loss: 0.1246 - mae: 0.1246 - val_loss: 0.7322 - val_mae: 0.7322\n",
      "Epoch 231/300\n",
      "12/12 [==============================] - 3s 288ms/step - loss: 0.1279 - mae: 0.1279 - val_loss: 0.7648 - val_mae: 0.7648\n",
      "Epoch 232/300\n",
      "12/12 [==============================] - 3s 290ms/step - loss: 0.1531 - mae: 0.1531 - val_loss: 0.7362 - val_mae: 0.7362\n",
      "Epoch 233/300\n",
      "12/12 [==============================] - 4s 291ms/step - loss: 0.1078 - mae: 0.1078 - val_loss: 0.7220 - val_mae: 0.7220\n",
      "Epoch 234/300\n",
      "12/12 [==============================] - 4s 295ms/step - loss: 0.0986 - mae: 0.0986 - val_loss: 0.7737 - val_mae: 0.7737\n",
      "Epoch 235/300\n",
      "12/12 [==============================] - 4s 291ms/step - loss: 0.0988 - mae: 0.0988 - val_loss: 0.7490 - val_mae: 0.7490\n",
      "Epoch 236/300\n",
      "12/12 [==============================] - 3s 289ms/step - loss: 0.1365 - mae: 0.1365 - val_loss: 0.7241 - val_mae: 0.7241\n",
      "Epoch 237/300\n",
      "12/12 [==============================] - 3s 287ms/step - loss: 0.1397 - mae: 0.1397 - val_loss: 0.7530 - val_mae: 0.7530\n",
      "Epoch 238/300\n",
      "12/12 [==============================] - 3s 289ms/step - loss: 0.1405 - mae: 0.1405 - val_loss: 0.7224 - val_mae: 0.7224\n",
      "Epoch 239/300\n",
      "12/12 [==============================] - 3s 285ms/step - loss: 0.1222 - mae: 0.1222 - val_loss: 0.7185 - val_mae: 0.7185\n",
      "Epoch 240/300\n",
      "12/12 [==============================] - 3s 289ms/step - loss: 0.1076 - mae: 0.1076 - val_loss: 0.7189 - val_mae: 0.7189\n",
      "Epoch 241/300\n",
      "12/12 [==============================] - 3s 289ms/step - loss: 0.1292 - mae: 0.1292 - val_loss: 0.7418 - val_mae: 0.7418\n",
      "Epoch 242/300\n",
      "12/12 [==============================] - 3s 288ms/step - loss: 0.1535 - mae: 0.1535 - val_loss: 0.7305 - val_mae: 0.7305\n",
      "Epoch 243/300\n",
      "12/12 [==============================] - 3s 289ms/step - loss: 0.1112 - mae: 0.1112 - val_loss: 0.7486 - val_mae: 0.7486\n",
      "Epoch 244/300\n",
      "12/12 [==============================] - 3s 288ms/step - loss: 0.0862 - mae: 0.0862 - val_loss: 0.7363 - val_mae: 0.7363\n",
      "Epoch 245/300\n",
      "12/12 [==============================] - 3s 287ms/step - loss: 0.1276 - mae: 0.1276 - val_loss: 0.7320 - val_mae: 0.7320\n",
      "Epoch 246/300\n",
      "12/12 [==============================] - 4s 292ms/step - loss: 0.1018 - mae: 0.1018 - val_loss: 0.7238 - val_mae: 0.7238\n",
      "Epoch 247/300\n",
      "12/12 [==============================] - 3s 285ms/step - loss: 0.1171 - mae: 0.1171 - val_loss: 0.7228 - val_mae: 0.7228\n",
      "Epoch 248/300\n",
      "12/12 [==============================] - 3s 289ms/step - loss: 0.1199 - mae: 0.1199 - val_loss: 0.7796 - val_mae: 0.7796\n",
      "Epoch 249/300\n",
      "12/12 [==============================] - 4s 297ms/step - loss: 0.1184 - mae: 0.1184 - val_loss: 0.7363 - val_mae: 0.7363\n",
      "Epoch 250/300\n",
      "12/12 [==============================] - 3s 290ms/step - loss: 0.0881 - mae: 0.0881 - val_loss: 0.7251 - val_mae: 0.7251\n",
      "Epoch 251/300\n",
      "12/12 [==============================] - 4s 291ms/step - loss: 0.1197 - mae: 0.1197 - val_loss: 0.7229 - val_mae: 0.7229\n",
      "Epoch 252/300\n",
      "12/12 [==============================] - 3s 289ms/step - loss: 0.1106 - mae: 0.1106 - val_loss: 0.7464 - val_mae: 0.7464\n",
      "Epoch 253/300\n",
      "12/12 [==============================] - 3s 290ms/step - loss: 0.1339 - mae: 0.1339 - val_loss: 0.7344 - val_mae: 0.7344\n",
      "Epoch 254/300\n",
      "12/12 [==============================] - 3s 287ms/step - loss: 0.1207 - mae: 0.1207 - val_loss: 0.7293 - val_mae: 0.7293\n",
      "Epoch 255/300\n",
      "12/12 [==============================] - 3s 287ms/step - loss: 0.0856 - mae: 0.0856 - val_loss: 0.7272 - val_mae: 0.7272\n",
      "Epoch 256/300\n",
      "12/12 [==============================] - 3s 285ms/step - loss: 0.1159 - mae: 0.1159 - val_loss: 0.7347 - val_mae: 0.7347\n",
      "Epoch 257/300\n",
      "12/12 [==============================] - 3s 288ms/step - loss: 0.0812 - mae: 0.0812 - val_loss: 0.7214 - val_mae: 0.7214\n",
      "Epoch 258/300\n",
      "12/12 [==============================] - 3s 289ms/step - loss: 0.1629 - mae: 0.1629 - val_loss: 0.7290 - val_mae: 0.7290\n",
      "Epoch 259/300\n",
      "12/12 [==============================] - 3s 290ms/step - loss: 0.1291 - mae: 0.1291 - val_loss: 0.7314 - val_mae: 0.7314\n",
      "Epoch 260/300\n",
      "12/12 [==============================] - 3s 288ms/step - loss: 0.1043 - mae: 0.1043 - val_loss: 0.7348 - val_mae: 0.7348\n",
      "Epoch 261/300\n",
      "12/12 [==============================] - 3s 286ms/step - loss: 0.1142 - mae: 0.1142 - val_loss: 0.7488 - val_mae: 0.7488\n",
      "Epoch 262/300\n",
      "12/12 [==============================] - 3s 289ms/step - loss: 0.0968 - mae: 0.0968 - val_loss: 0.7340 - val_mae: 0.7340\n",
      "Epoch 263/300\n",
      "12/12 [==============================] - 4s 291ms/step - loss: 0.1100 - mae: 0.1100 - val_loss: 0.7461 - val_mae: 0.7461\n",
      "Epoch 264/300\n",
      "12/12 [==============================] - 3s 288ms/step - loss: 0.1195 - mae: 0.1195 - val_loss: 0.7397 - val_mae: 0.7397\n",
      "Epoch 265/300\n",
      "12/12 [==============================] - 4s 291ms/step - loss: 0.1168 - mae: 0.1168 - val_loss: 0.7411 - val_mae: 0.7411\n",
      "Epoch 266/300\n",
      "12/12 [==============================] - 4s 293ms/step - loss: 0.1090 - mae: 0.1090 - val_loss: 0.7302 - val_mae: 0.7302\n",
      "Epoch 267/300\n",
      "12/12 [==============================] - 3s 290ms/step - loss: 0.1511 - mae: 0.1511 - val_loss: 0.7487 - val_mae: 0.7487\n",
      "Epoch 268/300\n",
      "12/12 [==============================] - 4s 291ms/step - loss: 0.1064 - mae: 0.1064 - val_loss: 0.7232 - val_mae: 0.7232\n",
      "Epoch 269/300\n",
      "12/12 [==============================] - 3s 289ms/step - loss: 0.0811 - mae: 0.0811 - val_loss: 0.7186 - val_mae: 0.7186\n",
      "Epoch 270/300\n",
      "12/12 [==============================] - 3s 289ms/step - loss: 0.1189 - mae: 0.1189 - val_loss: 0.7236 - val_mae: 0.7236\n",
      "Epoch 271/300\n",
      "12/12 [==============================] - 3s 289ms/step - loss: 0.1449 - mae: 0.1449 - val_loss: 0.7280 - val_mae: 0.7280\n",
      "Epoch 272/300\n",
      "12/12 [==============================] - 3s 289ms/step - loss: 0.1174 - mae: 0.1174 - val_loss: 0.7424 - val_mae: 0.7424\n",
      "Epoch 273/300\n",
      "12/12 [==============================] - 3s 286ms/step - loss: 0.0777 - mae: 0.0777 - val_loss: 0.7512 - val_mae: 0.7512\n",
      "Epoch 274/300\n",
      "12/12 [==============================] - 3s 287ms/step - loss: 0.1344 - mae: 0.1344 - val_loss: 0.7820 - val_mae: 0.7820\n",
      "Epoch 275/300\n",
      "12/12 [==============================] - 3s 284ms/step - loss: 0.1577 - mae: 0.1577 - val_loss: 0.7216 - val_mae: 0.7216\n",
      "Epoch 276/300\n",
      "12/12 [==============================] - 3s 290ms/step - loss: 0.1145 - mae: 0.1145 - val_loss: 0.7257 - val_mae: 0.7257\n",
      "Epoch 277/300\n",
      "12/12 [==============================] - 4s 290ms/step - loss: 0.1229 - mae: 0.1229 - val_loss: 0.7264 - val_mae: 0.7264\n",
      "Epoch 278/300\n",
      "12/12 [==============================] - 3s 287ms/step - loss: 0.1443 - mae: 0.1443 - val_loss: 0.7185 - val_mae: 0.7185\n",
      "Epoch 279/300\n",
      "12/12 [==============================] - 3s 288ms/step - loss: 0.1235 - mae: 0.1235 - val_loss: 0.7205 - val_mae: 0.7205\n",
      "Epoch 280/300\n",
      "12/12 [==============================] - 3s 289ms/step - loss: 0.1408 - mae: 0.1408 - val_loss: 0.7199 - val_mae: 0.7199\n",
      "Epoch 281/300\n",
      "12/12 [==============================] - 3s 289ms/step - loss: 0.1278 - mae: 0.1278 - val_loss: 0.7355 - val_mae: 0.7355\n",
      "Epoch 282/300\n",
      "12/12 [==============================] - 3s 289ms/step - loss: 0.1135 - mae: 0.1135 - val_loss: 0.7220 - val_mae: 0.7220\n",
      "Epoch 283/300\n",
      "12/12 [==============================] - 3s 289ms/step - loss: 0.0969 - mae: 0.0969 - val_loss: 0.7332 - val_mae: 0.7332\n",
      "Epoch 284/300\n",
      "12/12 [==============================] - 3s 287ms/step - loss: 0.1012 - mae: 0.1012 - val_loss: 0.7442 - val_mae: 0.7442\n",
      "Epoch 285/300\n",
      "12/12 [==============================] - 3s 288ms/step - loss: 0.1431 - mae: 0.1431 - val_loss: 0.7254 - val_mae: 0.7254\n",
      "Epoch 286/300\n",
      "12/12 [==============================] - 3s 288ms/step - loss: 0.1019 - mae: 0.1019 - val_loss: 0.7385 - val_mae: 0.7385\n",
      "Epoch 287/300\n",
      "12/12 [==============================] - 3s 286ms/step - loss: 0.1378 - mae: 0.1378 - val_loss: 0.7309 - val_mae: 0.7309\n",
      "Epoch 288/300\n",
      "12/12 [==============================] - 3s 289ms/step - loss: 0.1182 - mae: 0.1182 - val_loss: 0.7240 - val_mae: 0.7240\n",
      "Epoch 289/300\n",
      "12/12 [==============================] - 3s 289ms/step - loss: 0.1245 - mae: 0.1245 - val_loss: 0.7237 - val_mae: 0.7237\n",
      "Epoch 290/300\n",
      "12/12 [==============================] - 4s 294ms/step - loss: 0.1126 - mae: 0.1126 - val_loss: 0.7306 - val_mae: 0.7306\n",
      "Epoch 291/300\n",
      "12/12 [==============================] - 3s 289ms/step - loss: 0.1221 - mae: 0.1221 - val_loss: 0.7183 - val_mae: 0.7183\n",
      "Epoch 292/300\n",
      "12/12 [==============================] - 3s 285ms/step - loss: 0.0759 - mae: 0.0759 - val_loss: 0.7841 - val_mae: 0.7841\n",
      "Epoch 293/300\n",
      "12/12 [==============================] - 4s 290ms/step - loss: 0.1270 - mae: 0.1270 - val_loss: 0.7483 - val_mae: 0.7483\n",
      "Epoch 294/300\n",
      "12/12 [==============================] - 3s 288ms/step - loss: 0.1118 - mae: 0.1118 - val_loss: 0.7178 - val_mae: 0.7178\n",
      "Epoch 295/300\n",
      "12/12 [==============================] - 3s 291ms/step - loss: 0.1163 - mae: 0.1163 - val_loss: 0.7183 - val_mae: 0.7183\n",
      "Epoch 296/300\n",
      "12/12 [==============================] - 3s 287ms/step - loss: 0.1265 - mae: 0.1265 - val_loss: 0.7257 - val_mae: 0.7257\n",
      "Epoch 297/300\n",
      "12/12 [==============================] - 3s 288ms/step - loss: 0.1198 - mae: 0.1198 - val_loss: 0.7235 - val_mae: 0.7235\n",
      "Epoch 298/300\n",
      "12/12 [==============================] - 3s 290ms/step - loss: 0.1161 - mae: 0.1161 - val_loss: 0.7309 - val_mae: 0.7309\n",
      "Epoch 299/300\n",
      "12/12 [==============================] - 3s 288ms/step - loss: 0.1352 - mae: 0.1352 - val_loss: 0.7402 - val_mae: 0.7402\n",
      "Epoch 300/300\n",
      "12/12 [==============================] - 3s 288ms/step - loss: 0.1446 - mae: 0.1446 - val_loss: 0.7168 - val_mae: 0.7168\n",
      "INFO:tensorflow:Assets written to: ../saved_model/cnn_reg/assets\n"
     ]
    }
   ],
   "source": [
    "\n",
    "model = create_model()\n",
    "history = model.fit(train_x, train_y, validation_data = (val_x, val_y), batch_size=128, shuffle=True, epochs=300)\n",
    "model.save('../saved_model/cnn_reg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "id": "058f8cc2-8c96-4309-93c8-f45e43f9535a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8/8 [==============================] - 0s 17ms/step - loss: 0.7626 - mae: 0.7626\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.7625710964202881, 0.7625710964202881]"
      ]
     },
     "execution_count": 282,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trained_model = load_model('../saved_model/cnn_reg')\n",
    "trained_model.evaluate(test_x, test_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "id": "3c1b1c50-565d-4a11-9609-9152637c3071",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[6. 5. 2. 5. 2. 3. 4. 3. 4. 5. 2. 2. 5. 6. 6. 2. 5. 2. 2. 4. 4. 2. 2. 5.\n",
      " 2. 6. 6. 2. 2. 5. 6. 4. 4. 6. 5. 2. 2. 6. 6. 5. 2. 2. 2. 5. 4. 4. 4. 4.\n",
      " 2. 5. 2. 5. 2. 6. 6. 6. 2. 3. 3. 4. 4. 4. 4. 3. 3. 2. 6. 6. 6. 6. 6. 5.\n",
      " 2. 3. 3. 4. 4. 4. 3. 4. 3. 5. 2. 6. 6. 6. 6. 6. 5. 2. 4. 3. 4. 4. 3. 4.\n",
      " 3. 3. 4. 4. 2. 5. 6. 6. 6. 6. 2. 4. 4. 3. 3. 4. 4. 2. 6. 6. 6. 5. 5. 3.\n",
      " 3. 3. 4. 4. 3. 3. 3. 5. 5. 6. 6. 6. 5. 2. 5. 3. 3. 4. 3. 4. 4. 4. 3. 3.\n",
      " 3. 2. 5. 5. 6. 6. 6. 6. 5. 5. 3. 3. 4. 4. 3. 3. 3. 4. 3. 3. 4. 3. 5. 5.\n",
      " 6. 6. 6. 5. 5. 3. 4. 3. 3. 3. 3. 4. 3. 5. 5. 6. 2. 2. 5. 5. 2. 4. 6. 4.\n",
      " 3. 4. 3. 6. 4. 2. 5. 2. 5. 2. 2. 5. 5. 2. 4. 6. 3. 3. 6. 4. 2. 5. 5. 2.\n",
      " 2. 2. 5. 5. 4. 6. 3. 3. 6. 4. 5. 5. 2. 2. 6. 2. 5. 2. 5. 2. 5. 4. 6. 3.\n",
      " 3. 6. 4. 2. 5. 5. 5. 2. 2. 6.]\n",
      "[6 5 2 7 4 4 5 4 4 5 2 3 5 5 6 2 5 4 2 4 5 3 4 6 2 5 5 2 2 6 5 3 4 4 4 3 3\n",
      " 6 4 4 2 2 2 5 2 5 6 4 3 5 4 5 2 6 5 4 2 4 3 4 3 4 3 4 3 2 6 5 5 5 5 3 3 4\n",
      " 4 3 4 4 3 5 3 5 2 5 5 6 5 6 5 4 5 4 4 5 4 6 4 4 5 4 3 3 4 6 5 4 4 4 3 4 4\n",
      " 5 6 4 6 5 4 4 5 5 3 4 4 5 4 4 4 5 6 5 6 3 5 2 5 2 3 5 4 5 3 5 4 3 4 2 5 5\n",
      " 4 5 5 5 5 5 3 3 5 5 3 3 4 5 3 3 4 3 6 4 5 5 5 6 5 3 5 3 4 3 4 4 3 5 6 6 3\n",
      " 4 4 5 4 4 5 4 4 3 3 4 5 3 6 3 4 3 3 4 5 3 4 6 4 3 5 5 3 5 4 4 2 3 5 5 4 7\n",
      " 4 5 5 4 6 5 3 4 6 3 4 3 5 3 5 4 4 2 4 6 4 2 6 6 4 3 2 5]\n"
     ]
    }
   ],
   "source": [
    "predictions = trained_model.predict(test_x)\n",
    "# y = np.argmax(predictions, axis=1)\n",
    "# print(y)\n",
    "print(test_y)\n",
    "predictions = np.uint8(np.round(predictions)).flatten()\n",
    "# predictions[predictions>=6] = 6\n",
    "# predictions[predictions<=1] = 2\n",
    "print(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "id": "06100714-334a-419b-8f44-cdd0958214e5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 284,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAVoAAAD4CAYAAACt8i4nAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuNCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8QVMy6AAAACXBIWXMAAAsTAAALEwEAmpwYAAAk60lEQVR4nO3deXxU1f3/8ddnshBI2EFIQmpAKGIRoQJWEQVFFhVwoVGpSFsVvz83qGK1brVW6oKi0EIVKwgqCIVaZFFARHFlFRHCJouYEFbZwmIyM+f3R4YYSDILzM2ZO/08fdxHZu5k7ryN4ycnnzn3XDHGoJRSyjke2wGUUireaaFVSimHaaFVSimHaaFVSimHaaFVSimHJTr9AoVD+7pqWoPUqWk7QsT+O8Z2gsgN3LPQdgQVg7xF+XK6xyjesznsmpPUoNlpv144dESrlFIOc3xEq5RSVcrvs52gHC20Sqn44vPaTlCOFlqlVFwxxm87QjlaaJVS8cWvhVYppZylI1qllHKYfhimlFIO0xGtUko5y+isA6WUcph+GKaUUg7T1oFSSjksBj8M07UOlFLxxfjD34IQkSwRWSgia0VkjYgMDux/QkTyRWRlYLsyVCRXFNpqOfdQ44kJVB86qnSfJz2b6nc/S/X7R5Ly+0egWnWLCcuTWvVIuflhqv/fs1S/4xkSO/QoeSAllZT+D1L9zudJ6f8gpNSwG7SMX424netXjeaqD58u3fezqzty1cJn6J83kXptmlpMF1qP7l1Ys3oR63I/5Y8P3GU7TljcltkVeX3e8LfgvMD9xphWwK+Au0TknMBjLxpj2ga2OaEO5IpCW7xsAcde/csJ+6rl3M2PcyZy9IXBeL/5kuQu11pKVwm/n6IPJnH05Qc5Ov4Jktp3QxpkkHRRb3xbczk6Zii+rbkkXdTbdtJSm6cs4sPfDD9h3/51eSy6bSS7vlxvKVV4PB4Po0YO4+reN3PueV254YZraNWqhe1YQbkts2vy+v3hb0EYYwqMMSsCtw8Ba4HMU4nkikLr35yLOVJ4wj5Pw0z8m9cA4NvwNYltLrIRrVKmcD/+HVtL7hQdw79nO1KzHoktz8e76hMAvKs+IbFle3shT7Jr8XqK9p34cz747XYObSqwlCh8HTu0Y9OmrWzZso3i4mKmTp1Bn949bMcKym2Z3ZLXGF/Ym4gMEpFlZbZBFR1TRLKBdsDiwK67RWSViIwTkbqhMoUstCJytog8KCKjRGRk4HarSP7FneDfsY2EX3QEIPG8i5DaDSwnqpzUboCn8Zn48zchqbUwhfuBkmIsNWrZDRcnMjIb833e9tL7efkFZGQ0tpgoNLdldk3eCHq0xpixxpj2ZbaxJx9ORNKA6cAQY8xB4J/AWUBboAB4IVSkoIVWRB4E3gYEWAIsDdyeLCIPBXle6W+Jcau2hspwSo5NGUXSRVdSfcgLJf1ZX7Ejr3PakqpRrd9giua9CUVHbaeJWyLlF8o3JrYv7uG2zK7JG6XWAYCIJFFSZN8yxvwHwBiz0xjjMyXLhL0KdAx1nFDTu24FfmGMOaGKicgIYA3wTEVPCvxWGAvOXcrG7M7n2KtPlORpkEFiq9j5E7yUJ4Fq/QbjXf05vvXLADCHDyJpdUpGs2l1MEcOWg4ZH/LzCshqklF6v0lmOgUFOy0mCs1tmV2TN0rzaKXkN8trwFpjzIgy+9ONMcf7adcCq0MdK1TrwA9kVLA/PfCYNZJWO3BDSO6WQ/EX79uMU6Hkq2/D7NmOd/F7pfu8G1aQ2KYzAIltOuNdv9xWvLiydNlKmjdvSnZ2FklJSeTk9GXmrHm2YwXltsyuyesrDn8LrhMwALjspKlcz4nINyKyCugK/CHUgUKNaIcAC0RkI/B9YN/PgObA3aEOHi3VfnM/CWe1RlJrUePR1yiaNxlJTiGpU8n0Ne83X+JduqCq4oTFk/Vzktp0xr9zGym3DQOgeOFUij+fScp195DY9lLMgb0cmz4qxJGqTqcxd9HowlZUq5fGtctGseqF6fy47zAdnrqFavVr0uWNoexb8x0L+z9nO2o5Pp+PwUMeZc7sSSR4PLw+YQq5uRtsxwrKbZldkzdKp+AaYz6lpFV6spDTuU4moXosIuKhpAeRGXjRPGCpMSas0y/0KrjO06vgqngRjavgHvtictg1J+XCm6rkKrghT8ENNHy/rIIsSil1+nRRGaWUcpgWWqWUcpaJwameWmiVUvFFl0lUSimHaetAKaUcpiNapZRymI5olVLKYTqiVUoph3n1KrhKKeUsHdEqpZTDtEerlFIO0xGtUko57H9xRHv2uE1Ov0RUrb+vre0IEfv1p/fajhCxB9uvtB0hIjsK99mOoMKlI1qllHKYzjpQSimHxeB1zLTQKqXiy/9ij1YppaqUFlqllHKYfhimlFIO84V1OcMqpYVWKRVftHWglFIO00KrlFIO0x6tUko5y/h1Hq1SSjlLWwdKKeUwnXWglFIO0xGtUko5TAvt6UvPbMzIMX+jYaMG+P1+Jk2YxmuvvGk7VjlSqx7V+vwfklYbjKF4xUK8S+dCSiop192N1GmI2b+bY//5Oxw7YjsuO3bv5eHnX2HPvgN4ROjXqys3X9MDgLdmzOPtmfNJSEjgko7ncd+tN1lOW55b3hcn69G9CyNGPEmCx8O48ZN5bvho25GCckVeXVTm9Pm8Xp58bDirV60lNa0G7304lUUffc7G9ZttRzuR30/RB5Pw79gKySlUv/Wv+LZ8Q2KbS/BtzaX485kkXdSbpIt6U/zhFNtpSUhIYOjt/TmneTaHjxzlhnsf58J2rdm7/wALv1zB9DF/Izk5ib37D9iOWiHXvC/K8Hg8jBo5jJ5X3kReXgFffjGHmbPmsXbtRtvRKuSavDE4ovXYDhCpXTv3sHrVWgAOFx5h44bNNE5vZDlVeaZwf0mRBSg6hn/PdqRmPRJbno931ScAeFd9QmLL9vZCltGwXh3OaZ4NQGqN6jTNymDn3h+YMnsBt+ZcTXJyEgD169S2mLJybnlflNWxQzs2bdrKli3bKC4uZurUGfTp3cN2rEq5Jq/fhL9VkVMutCLyu2gGORVNsjJo3aYVXy1fZTtKUFK7AZ7GZ+LP34Sk1sIU7gdKirHUqGU3XAXyd+5m3abvaNOyOd/l72DF6vX0H/JnfvvAU6yO4RHicW55X2RkNub7vO2l9/PyC8jIaGwxUXCuyevzhb8FISJZIrJQRNaKyBoRGRzYX09E5ovIxsDXuqEinc6I9i9BAg4SkWUisuzwjz+cxktUrkZqdcZOeJEnHn6WwkOHHXmNqEiqRrV+gyma9yYUHbWdJqQjR4/xh6dG8eAdvyEttTo+n4+DhYd568UnuP+2mxj69N8xMdgDO8417wtARMrti+WfrVvyGr8/7C0EL3C/MaYV8CvgLhE5B3gIWGCMaQEsCNwPKmiPVkQqGxIIUOnfZcaYscBYgCb1Wkf9v0RiYiJjJ7zEO9Nm896sD6J9+OjxJFCt32C8qz/Ht34ZAObwQSStTsloNq0O5shByyF/Uuz18oenRnFV14vo1qkDAI0a1KNbpw6ICOe2PAsRD/sOHKJendgbibvmfRGQn1dAVpOM0vtNMtMpKNhpMVFwrskbpZaAMaYAKAjcPiQia4FMoC/QJfBtE4CPgAeDHSvUiLYRcAvQu4Jt7ymlj4LnRz3Jtxs28+qYibYihCX56tswe7bjXfxe6T7vhhUktukMQGKbznjXL7cV7wTGGP780r9olpXBwOt6le6/7MLzWbwyF4CteQUUe73UrV3TVsyg3PK+OG7pspU0b96U7OwskpKSyMnpy8xZ82zHqpRr8hp/2FvZv74D26CKDiki2UA7YDHQKFCEjxfjM0JFCjXrYBaQZoxZWcELfxTq4E7ocEE7+t3Yh7VrNjD342kAPPvXkXz4wSc24lTKk/Vzktp0xr9zGym3DQOgeOFUij+fScp195DY9lLMgb0cmz7KctISX63ZwMwFn9EiO4t+dz0CwL0Df8213S/lsRdf5dr/e4ikxESG3T+owj8hbXPL+6Isn8/H4CGPMmf2JBI8Hl6fMIXc3A22Y1XKNXkjGNGW/eu7MiKSBkwHhhhjDp7K+1+c7rE40TpwkhsvN57U332XG2/W/ve2I0RELzdeNbxF+af9W/zw4zeGXXNSn3w76OuJSBIlA865xpgRgX3rgS7GmAIRSQc+Msa0DHYc103vUkqpoCJoHQQjJUPX14C1x4tswLvAwMDtgcCMUJFcd8KCUkoFFb35sZ2AAcA3IrIysO9h4BlgqojcCmwDfh3qQFpolVJxJYxpW+Edx5hPKZlhVZHLIzmWFlqlVHzRhb+VUsphWmiVUsphuvC3Uko5S68ZppRSTtNCq5RSDovB9Wi10Cql4ouOaJVSymFaaJVSylnG9z/YOjjkgsWuyxryrx9tR4jYyLruWBawrDV9Y3Bl/iAumpNqO0LE1u/Lsx3BDh3RKqWUs3R6l1JKOU0LrVJKOSz2WrRaaJVS8cV4Y6/SaqFVSsWX2KuzWmiVUvFFPwxTSimn6YhWKaWcpSNapZRymo5olVLKWcZrO0F5WmiVUnElxFXErdBCq5SKL1polVLKWTqiVUoph2mhjYJ/jHmGnr0uY/fuvVzYsZftOGFp1CyDO/7xh9L7DbLOYMaLU1gwbo7FVCfacegYj81bzd4jRYjA9a2b0L/tz5i/cScvL97Elh8O88YNHflFo9q2o5aq/vuhJJ53Aebgfgofux0AT9ZZVB84BElKwvh8HHtjFL4t6y0nrVhytWQmzniZ5ORkEhISmDfrQ0YPf9V2rKB6dO/CiBFPkuDxMG78ZJ4bPtp2pHKMT2xHKMd1hXbSW9N59ZU3ePnV521HCdvOzdt58soHABCPh+GLX+GruUsspzpRgke4r/PPaXVGLQ4Xeen/9mIuyKrHWfVTeeGq83jqw7W2I5ZT9OlcflzwX2rc9mDpvpSc2/lxxkS83ywlsU1HUnIGcfjZ+y2mrFzRj0X8/rq7OHLkKImJCbwxcyyffPgFq5avth2tQh6Ph1Ejh9HzypvIyyvgyy/mMHPWPNau3Wg72glicUTrCfUNInK2iFwuImkn7e/pXKzKff7ZUvbt22/jpaOiVafW7P5uBz/k77Ed5QQNU6vR6oxaAKQmJ9K0biq7D/9Is3ppZNeNzUWvfRu+wRQeKrdfqqeWfvXv31vVsSJy5EjJwviJSYkkJiZiTOxNtj+uY4d2bNq0lS1btlFcXMzUqTPo07uH7VjlGL+EvVWVoIVWRO4FZgD3AKtFpG+Zh//mZLB41aF3J5a8+5ntGEFtP3iU9bsP0TqG2gThOjZpDCk5g6j5wiRSbriDY9P+ZTtSUB6Ph+kL3uCTNe/zxcdL+GbFGtuRKpWR2Zjv87aX3s/LLyAjI/aulGH84W9VJdSI9nbgfGPMNUAX4DERGRx4rNJfByIySESWiciyouKDUQkaDxKSEjmvW3uWzfnCdpRKHSnyMnT21wy95OekVXNdZ4nkrr05OvmfHLq/P8cm/5MavxtqO1JQfr+f6y8fwGVte3PuL39B87Ob2Y5UKZHy/8vH4gjcGAl7qyqhCm2CMaYQwBizlZJi20tERhCk0Bpjxhpj2htj2icn1YpWVtdr3aUt21Zv4dCeA7ajVKjY52fonFX0apnO5c0b2Y5zSpI7dce7/BMAipd+TEKzlpYThefQwUKWfLaci7teaDtKpfLzCshqklF6v0lmOgUFOy0mqpgbR7Q7RKTt8TuBons10AA418Fccaljn4tZMvNT2zEqZIzhLwtyaVovlQG/PNN2nFPm37+HhJbnAZDQqh3+nfmWE1Wubv061KxV8tFHtZRqXHhJR7Z8u9VuqCCWLltJ8+ZNyc7OIikpiZycvsycNc92rHL8Pgl7qyqh/ja8BTjhzGFjjBe4RURecSxVEK+Nf4mLO19A/fp1yV3/KU8PG8kbE/9tI0pEklOSOefiNrz58FjbUSq0smA/s9cV0KJ+GjdMKmlt3H1Rc4p9hmc/Wse+o0Xc++5KWjasyZhrfmk5bYnqdzxM4tnnIWm1qfnCZI79dwJHX3+R6v3vBE8CpriII6+/aDtmpRo2asDfRj2OJ8GDx+Nh7owFfDw/dvv3Pp+PwUMeZc7sSSR4PLw+YQq5uRtsxyonmh9yicg4SgaXu4wxrQP7nqCkrbo78G0PG2OCztUUp3sstdPOir0mThA5DWKjiERi5APu+zO/eNk62xEictGc8rMbYp0bLzfuLco/7Sq5te0VYdec7JXzg76eiFwCFAITTyq0hcaYsOeYuu/TDqWUCiKaY0djzCIRyT7d44ScR6uUUm4SyTzasjOkAtugMF/mbhFZJSLjRKRuqG/WQquUiiuRTO8qO0MqsIXzIco/gbOAtkAB8EKoJ2jrQCkVV3wOzyYwxpTOaRORV4FZoZ6jhVYpFVecPhFBRNKNMQWBu9cCIRen0EKrlIorUZ7eNZmSE7UaiEge8GegS+D8AgNsBe4IdRwttEqpuBLlWQc3VbD7tUiPo4VWKRVXqnJVrnBpoVVKxRWfP/YmU2mhVUrFlRhcUEwLrVIqvvircPnDcGmhVUrFlapcZzZcWmiVUnHlf7J1cLjomNMvEVXvHYy9ixCGct4z1WxHiNgdX8XmcpGV+X8fPG47QsQeSY6t69JVFW0dKKWUw3TWgVJKOSwGOwdaaJVS8UVbB0op5TCddaCUUg6rwovbhk0LrVIqrhh0RKuUUo7yautAKaWcpSNapZRymPZolVLKYTqiVUoph+mIVimlHObTEa1SSjkrBq9k485C26N7F0aMeJIEj4dx4yfz3PDRtiMFlZ7ZmJFj/kbDRg3w+/1MmjCN115503asci57/nayL2/L0b0HmdztTwBUq5NKj9F3UyurIQe/383cO//OjweOWE5aomDnbh7+6/Ps+WEfHhH69e3FgJxruP+xp9m6LQ+AQ4WF1ExLY/qE2HiPuO1nfLJ/jHmGnr0uY/fuvVzYsZftOBXyx+CINvaWuQnB4/EwauQwru59M+ee15UbbriGVq1a2I4VlM/r5cnHhtP1V33o070/A2+9kRYtm9mOVc66fy9i5oDhJ+w7/87e5H2Wy5uXDCXvs1x+eWdvS+nKS0xI4IF7bmfmpLFMGvsib/9nFpu2fMcLf/0T0yeMZvqE0VzR5WK6XXqR7ail3PYzPtmkt6Zz/TW/sx0jKBPBVlVCFloR6SgiHQK3zxGR+0TkSuejVaxjh3Zs2rSVLVu2UVxczNSpM+jTu4etOGHZtXMPq1eVrHN7uPAIGzdspnF6I8upytu+eD3H9heesK9p9/NZN+0TANZN+4RmPdrbiFahhg3qcU7L5gCkptag2ZlZ7Ny9t/RxYwzvf7iIK6/oYilheW77GZ/s88+Wsm/fftsxgvJHsFWVoK0DEfkz0AtIFJH5wAXAR8BDItLOGDPM+YgnyshszPd520vv5+UX0LFDu6qOccqaZGXQuk0rvlq+ynaUsNRoUIsju/YDcGTXfqrXr2U3UCXyC3ayduMm2vyiZem+5V+vpn7dupyZlWkxWWhu+Rm7hV9ir3UQqkfbD2gLVAN2AE2MMQdFZDiwGKiw0IrIIGAQgCTUxuNJjVpgqeCHaGLx2hUVqJFanbETXuSJh5+l8NBh23HixpEjR/nDI0/x4L13kJb603ttzvyPuPKKSy0mUzb4bAeoQKjWgdcY4zPGHAE2GWMOAhhjjhJk5G2MGWuMaW+MaR/NIguQn1dAVpOM0vtNMtMpKNgZ1ddwQmJiImMnvMQ702bz3qwPbMcJ25E9B6lxRh0AapxRh6N7D9oNdJJir5chjzzFVd27ckWXTqX7vV4fH3z8OT0vv8RiuvDE+s/YbfwS/lZVQhXaIhGpEbh9/vGdIlIbS/OCly5bSfPmTcnOziIpKYmcnL7MnDXPRpSIPD/qSb7dsJlXx0y0HSUiW+av4Ox+nQE4u19ntsxbbjnRT4wxPP70SzQ7M4uBN153wmNfLvuKZmc2ofEZDS2lC18s/4zdyI+EvVWVUIX2ksBoFmNM2cKaBAx0LFUQPp+PwUMeZc7sSaxe9RHTps0kN3eDjShh63BBO/rd2IdOnS9g7sfTmPvxNC7r1tl2rHK6/+Mu+v33Ceo0S+e3S0bR6oZLWTF6JlmdW3PzoufJ6tya5WNm2o5Z6qtVa5j5/gIWr/ia6wfexfUD72LR50sAeO+Dj+nVrYvdgBVw28/4ZK+Nf4n5H06jRYum5K7/lAG3/Np2pHJicdaBON3fTEzOdEcDNaBxWl3bESL2UGpb2xEidsdXT9qOEJFX2rnwKrj7vrAdIWIHCjed9jBzYubNYdecW/LfrJJhrStPWFBKqcroWgdKKeUwX+zN7nLfmWFKKRVMNE9YEJFxIrJLRFaX2VdPROaLyMbA15D9Ri20Sqm4EuUzw14Hep607yFggTGmBbAgcD8oLbRKqbhiJPwt5LGMWQT8cNLuvsCEwO0JwDWhjqOFVikVVyIZ0YrIIBFZVmYbFMZLNDLGFAAEvp4R6gn6YZhSKq5EcgquMWYsMNapLMdpoVVKxZUqOLV2p4ikG2MKRCQd2BXqCdo6UErFlSpYJvFdfjozdiAwI9QTdESrlIor0TxhQUQmA12ABiKSB/wZeAaYKiK3AtuAkOcha6FVSsWVaJ7zb4y5qZKHLo/kOFpolVJxRS/OqJRSDovFhb+10J7kUNFR2xEidqCmqxZIA8CXv852hIhcknDAdgQVJn+VLoAYHi20Sqm4oqt3KaWUw2JvPKuFVikVZ3REq5RSDvNK7I1ptdAqpeJK7JVZLbRKqTijrQOllHKYTu9SSimHxV6Z1UKrlIoz2jpQSimH+WJwTKuFVikVV3REq5RSDjM6olVKKWfpiDZKenTvwogRT5Lg8TBu/GSeGz7adqSg/jHmGXr2uozdu/dyYcdetuOEpcPvetD2pq6ICF9NXsjSce/bjlTOjj37eGT0JPbuP4iI0K/bhfzmykv559T3mb7gS+rVSgXgnpuuovMvz7GctkST5+6l1mUd8O49wIYed5/wWIPbryXjkd+zpt1v8O07aClhcG54L8fi9C7XXTPM4/EwauQwru59M+ee15UbbriGVq1a2I4V1KS3pnP9Nb+zHSNsDX/ehLY3dWV8n8d5teefaHF5O+pmN7Idq5yEBA9DB/Thvy/+iTeHDeHtuZ+xKW8HAAOuupSpwx9g6vAHYqbIAuybtoAtA58otz8pvQE1O7elKC/kdf6scsN72USwVRXXFdqOHdqxadNWtmzZRnFxMVOnzqBP7x62YwX1+WdL2bdvv+0YYavfPIPtX32L91gRxudn2+K1tOzRwXaschrWrU2rZlkApFZPoVlmI3b9ENvrxh5esgbvgUPl9qc/dhsFT48nNmeB/sQN72UvJuytqkRcaEVkohNBwpWR2Zjv87aX3s/LLyAjo7HFRPFn94Y8sjqeTfU6aSSmJHNW17bUyqhnO1ZQ+bt+YN2WPM5tfiYAb8/9hH5Dn+PxMZM5WHjEcrrganXriHfnXo6t3Wo7SlwwEfxTVYL2aEXk3ZN3AV1FpA6AMaZPJc8bBAwCkITaeDypp5/0p2OX22dMbI8C3Gbvt9v54uWZ9H/rIYoO/8iu3G34vbH4EUOJI8d+5P4XxvPAb68lrUYKOd07MahfdwQYPeU9np84gyfvrOwae3ZJSjXOuDuHzQMetx0lbsTiOzXUh2FNgFzgX5T8TSNAe+CFYE8yxowFxgIkJmdGtQrm5xWQ1STjp4CZ6RQU7IzmSyjg6ykf8/WUjwHo8kAOh3b8YDlRxYq9Pu57YTxXdj6fbhe0AaB+nZqlj193+YXc8+yrtuKFVO3MxiQ3acTP3xsFQFLjBrSY9RLfXnMf3t377YZzqVic3hWqddAeWA48AhwwxnwEHDXGfGyM+djpcBVZumwlzZs3JTs7i6SkJHJy+jJz1jwbUeJajfq1AKiVUZ+WPTuwZsbnlhOVZ4zhiZffpllmI265ukvp/t37furTfrhkFc2z0i2kC8+x9d+R234A6y6+jXUX30bxjj1svHqIFtnT4I9gqypBR7TGGD/wooj8O/B1Z6jnOM3n8zF4yKPMmT2JBI+H1ydMITd3g81IIb02/iUu7nwB9evXJXf9pzw9bCRvTPy37VhBXf/yYKrXrYm/2Mvcx1/n2MHY63N+tX4LsxYto8XP0sl5YDhQMpXrvc9WsH7rdkQgo2E9Hhv0a8tJf/KzUUNJ/dW5JNatxdlfjGfni5PYN3W+7Vhhc8N72ReDrUSJpL8pIlcBnYwxD4f7nGi3DpyWmpxiO0LE/lj/V7YjROz+d39jO0JENvT9p+0IEeu8J9d2hIgdKNxU/kOYCPU/89qwa86k79457dcLR0SjU2PMbGC2Q1mUUuq0xWKP1pVnhimlVGXcOOtAKaVcJRZPwdVCq5SKK9o6UEoph8XirAMttEqpuKKtA6WUclg0PwwTka3AIcAHeI0x7U/lOFpolVJxxYEebVdjzJ7TOYAWWqVUXInF1oHr1qNVSqlgjDFhb+EcDpgnIssDqxKeEh3RKqXiSiSXGy+7pGvA2MDqg8d1MsZsF5EzgPkiss4YsyjSTFpolVJxJZLWQdklXSt5fHvg6y4ReQfoCERcaLV1oJSKK9FqHYhIqojUPH4b6A6sPpVMEa3edSrctnqXUsoeb1H+aa+m1bXJFWHXnIV58yt9PRFpBrwTuJsITDLGDDuVTNo6UErFlWhN7zLGbAbOi8axtNAqpeKKnoKrlFIOi8V5tFpolVJxRQutUko5zOkP+E+FFlqlVFzREa1SSjlMF/5WSimH+UzsXTVMC61SKq5oj1YppRymPVqllHKY9miVUsphfm0dKKWUs3REq5RSDovFWQeuXI+2R/curFm9iHW5n/LHB+6yHScsbsvstrygmauCG/L6jQl7qyquW4/W4/Gwds0n9LzyJvLyCvjyizncPOBO1q7dGM2XiSq3ZXZbXtDMVaEq8kZjPdoWDc8Pu+Zs3L38tF8vHBGNaEXkYhG5T0S6OxUolI4d2rFp01a2bNlGcXExU6fOoE/vHrbihMVtmd2WFzRzVXBL3lgc0QYttCKypMzt24F/ADWBP4vIQw5nq1BGZmO+z9teej8vv4CMjMY2ooTNbZndlhc0c1VwS14TwT9VJdSHYUllbg8CrjDG7BaR54EvgWcqelLZK0tKQm08ntRoZD1+7HL7YvFMkLLcltlteUEzVwW35PUZn+0I5YQqtB4RqUvJyFeMMbsBjDGHRcRb2ZPKXlky2j3a/LwCsppklN5vkplOQcHOaL5E1Lkts9vygmauCm7JG4vFP1SPtjawHFgG1BORxgAikgZUSRP5ZEuXraR586ZkZ2eRlJRETk5fZs6aZyNK2NyW2W15QTNXBbfk9WPC3qpK0BGtMSa7kof8wLVRTxMGn8/H4CGPMmf2JBI8Hl6fMIXc3A02ooTNbZndlhc0c1VwS95YHNG6bnqXUip+RWN6V3qdc8KuOQX7c6vkL3M9M0wpFVf0FFyllHJYLJ6Cq4VWKRVXYrFHq4VWKRVXdJlEpZRymI5olVLKYXopG6WUcpiOaJVSymE660AppRymH4YppZTDYrF14MpL2SilVGWiuR6tiPQUkfUi8u3prMGtI1qlVFyJ1ohWRBKA0cAVQB6wVETeNcbkRnosLbRKqbgSxR5tR+BbY8xmABF5G+gLxF6hjcZqPJURkUGBRcZdwW15wX2Z3ZYXNHO0RVJzyl4NJmBsmX+vTOD7Mo/lARecSia392gHhf6WmOK2vOC+zG7LC5rZGmPMWGNM+zJb2V8eFRXsUxouu73QKqWUU/KArDL3mwDbK/neoLTQKqVUxZYCLUSkqYgkAzcC757Kgdz+YVhM9oiCcFtecF9mt+UFzRyTjDFeEbkbmAskAOOMMWtO5ViOX8pGKaX+12nrQCmlHKaFVimlHObKQhut0+KqioiME5FdIrLadpZwiEiWiCwUkbUiskZEBtvOFIqIpIjIEhH5OpD5L7YzhUNEEkTkKxGZZTtLOERkq4h8IyIrRWSZ7Txu4boebeC0uA2UOS0OuOlUTourKiJyCVAITDTGtLadJxQRSQfSjTErRKQmsBy4JsZ/xgKkGmMKRSQJ+BQYbIz50nK0oETkPqA9UMsYc7XtPKGIyFagvTFmj+0sbuLGEW3paXHGmCLg+GlxMcsYswj4wXaOcBljCowxKwK3DwFrKTlLJmaZEoWBu0mBLaZHESLSBLgK+JftLMpZbiy0FZ0WF9NFwM1EJBtoByy2HCWkwJ/hK4FdwHxjTKxnfgn4IxB7K1VXzgDzRGR54PRVFQY3FtqonRanghORNGA6MMQYc9B2nlCMMT5jTFtKzuDpKCIx26YRkauBXcaY5bazRKiTMeaXQC/grkBbTIXgxkIbtdPiVOUCfc7pwFvGmP/YzhMJY8x+4COgp90kQXUC+gR6nm8Dl4nIm3YjhWaM2R74ugt4h5JWngrBjYU2aqfFqYoFPlh6DVhrjBlhO084RKShiNQJ3K4OdAPWWQ0VhDHmT8aYJsaYbErewx8aY262HCsoEUkNfDiKiKQC3QFXzKSxzXWF1hjjBY6fFrcWmHqqp8VVFRGZDHwBtBSRPBG51XamEDoBAygZZa0MbFfaDhVCOrBQRFZR8st4vjHGFVOmXKQR8KmIfA0sAWYbY963nMkVXDe9Syml3MZ1I1qllHIbLbRKKeUwLbRKKeUwLbRKKeUwLbRKKeUwLbRKKeUwLbRKKeWw/w/W93YIUHl1BQAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "cf = confusion_matrix(test_y, predictions)\n",
    "sn.heatmap(cf, annot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "id": "b2e02c95-f8a4-4c2b-84a4-d429bba27dd4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5, 48, 48)\n",
      "(5,)\n",
      "[2. 2. 2. 4. 4.]\n",
      "[4.817904  5.4316936 5.052975  3.8388755 4.7216563]\n"
     ]
    }
   ],
   "source": [
    "emoji_x, emoji_y = load_data('../plots/predict')\n",
    "emoji_x = emoji_x.reshape(-1, 48, 48, 1)\n",
    "emoji_pred = trained_model.predict(emoji_x)\n",
    "# y = np.argmax(predictions, axis=1)\n",
    "# print(y)\n",
    "print(emoji_y)\n",
    "# emoji_pred = np.uint8(np.round(emoji_pred)).flatten()\n",
    "emoji_pred = emoji_pred.flatten()\n",
    "# predictions[predictions>=6] = 6\n",
    "# predictions[predictions<=1] = 2\n",
    "print(emoji_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "id": "a0bed25e-5a5f-44b0-8a03-c83fd252c1d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_plot(plot_path):\n",
    "    trained_model = load_model('../saved_model/cnn_reg')\n",
    "    plot_name = plot_path.split('/')[-1]\n",
    "    plot_name_split = plot_name.split('_')\n",
    "    print('number of cluster:', plot_name_split[0])\n",
    "    plot = get_binary_plot(plot_path)\n",
    "    resized = cv2.resize(plot, (48,48), interpolation=cv2.INTER_AREA) # resize to 32 * 32\n",
    "    scaled = resized/255.0 # rescale\n",
    "    scaled = scaled.reshape(-1, 48, 48, 1)\n",
    "    pred = trained_model.predict(scaled)\n",
    "    print('predict:', pred)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 294,
   "id": "3a24dda8-7bfb-493a-b793-753d7159a578",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of cluster: unknow\n",
      "predict: [[2.456901]]\n"
     ]
    }
   ],
   "source": [
    "predict_plot('../plots/predict/unknow_5.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8fb16e8-c0e5-4a4c-aba7-4c88edee1ce6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
